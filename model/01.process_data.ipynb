{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear  Tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Cargar los archivos JSON de entrada y salida\n",
    "with open(\"../data/processed/model/input_data.json\", \"r\") as f:\n",
    "    input_data_json = json.load(f)\n",
    "\n",
    "with open(\"../data/processed/model/reference_data.json\", \"r\") as f:\n",
    "    output_data_json = json.load(f)\n",
    "\n",
    "# Agrupar los datos por scenario_id\n",
    "input_by_scenario = defaultdict(list)\n",
    "output_by_scenario = defaultdict(list)\n",
    "\n",
    "# Agrupar datos de entrada por scenario_id\n",
    "for entry in input_data_json:\n",
    "    scenario_id = entry[\"scenario_id\"]\n",
    "    input_by_scenario[scenario_id].append(entry)\n",
    "\n",
    "# Agrupar datos de salida por scenario_id\n",
    "for entry in output_data_json:\n",
    "    scenario_id = entry[\"scenario_id\"]\n",
    "    output_by_scenario[scenario_id].append(entry)\n",
    "\n",
    "# Obtener la lista de escenarios (deberían ser 68)\n",
    "scenarios = sorted(input_by_scenario.keys())\n",
    "if len(scenarios) != 68:\n",
    "    print(f\"Advertencia: Se esperaban 68 escenarios, pero se encontraron {len(scenarios)}\")\n",
    "\n",
    "# Crear listas para almacenar los datos de entrada y salida\n",
    "input_data = []\n",
    "target_data = []\n",
    "\n",
    "# Función para convertir valores a float de manera segura\n",
    "def safe_float(value, default=0.0):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "# Procesar cada escenario\n",
    "for scenario_id in scenarios:\n",
    "    scenario_inputs_list = input_by_scenario[scenario_id]\n",
    "    scenario_outputs_list = output_by_scenario[scenario_id]\n",
    "\n",
    "    # Verificar que el número de pares coincida entre entrada y salida\n",
    "    if len(scenario_inputs_list) != len(scenario_outputs_list):\n",
    "        print(f\"Advertencia: El escenario {scenario_id} tiene {len(scenario_inputs_list)} entradas y {len(scenario_outputs_list)} salidas\")\n",
    "\n",
    "    scenario_inputs = []\n",
    "    scenario_targets = []\n",
    "\n",
    "    # Procesar cada par de relés en el escenario (hasta 100)\n",
    "    num_pairs = min(len(scenario_inputs_list), 100)\n",
    "    for pair_idx in range(num_pairs):\n",
    "        pair_input = scenario_inputs_list[pair_idx]\n",
    "        pair_output = scenario_outputs_list[pair_idx] if pair_idx < len(scenario_outputs_list) else None\n",
    "\n",
    "        # Datos de entrada\n",
    "        inputs = [\n",
    "            # safe_float(pair_input[\"fault\"]),\n",
    "            safe_float(pair_input[\"main_relay\"][\"Ishc\"]),\n",
    "            safe_float(pair_input[\"main_relay\"][\"Time_out\"]),\n",
    "            safe_float(pair_input[\"main_relay\"][\"current_a\"]),\n",
    "            safe_float(pair_input[\"backup_relay\"][\"Ishc\"]),\n",
    "            safe_float(pair_input[\"backup_relay\"][\"Time_out\"]),\n",
    "            safe_float(pair_input[\"backup_relay\"][\"current_a\"])\n",
    "        ]\n",
    "        scenario_inputs.append(inputs)\n",
    "\n",
    "        # Datos de salida (si existen)\n",
    "        if pair_output:\n",
    "            targets = [\n",
    "                safe_float(pair_output[\"main_relay\"][\"pick_up\"]),\n",
    "                safe_float(pair_output[\"main_relay\"][\"TDS\"]),\n",
    "                safe_float(pair_output[\"backup_relay\"][\"pick_up\"]),\n",
    "                safe_float(pair_output[\"backup_relay\"][\"TDS\"])\n",
    "            ]\n",
    "        else:\n",
    "            targets = [0.0] * 4  # Rellenar con ceros si no hay salida correspondiente\n",
    "        scenario_targets.append(targets)\n",
    "\n",
    "    # Rellenar con ceros si hay menos de 100 pares\n",
    "    while len(scenario_inputs) < 100:\n",
    "        scenario_inputs.append([0.0] * 6)\n",
    "        scenario_targets.append([0.0] * 4)\n",
    "\n",
    "    input_data.append(scenario_inputs)\n",
    "    target_data.append(scenario_targets)\n",
    "\n",
    "# Convertir las listas a tensores de PyTorch\n",
    "input_tensor = torch.tensor(input_data, dtype=torch.float32)  # Forma: (68, 100, 6)\n",
    "target_tensor = torch.tensor(target_data, dtype=torch.float32)  # Forma: (68, 100, 4)\n",
    "\n",
    "# Verificar las formas de los tensores\n",
    "print(\"Forma del tensor de entrada:\", input_tensor.shape)\n",
    "print(\"Forma del tensor de salida:\", target_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación del transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando y preprocesando datos...\n",
      "Archivos .pt no encontrados, generando datos de ejemplo...\n",
      "Datos de ejemplo generados.\n",
      "Forma Input Tensor Original: torch.Size([500, 74, 6])\n",
      "Forma Target Tensor Original: torch.Size([500, 74, 4])\n",
      "Normalizando datos...\n",
      "Datos normalizados correctamente.\n",
      "Dividiendo datos...\n",
      "\n",
      "============================================================\n",
      "--- DETALLES DE LA DIVISIÓN DE DATOS ---\n",
      "Número total de escenarios originales: 500\n",
      "Porcentaje para validación (test_size): 20.0%\n",
      "Semilla aleatoria (random_state): 42\n",
      "------------------------------------------------------------\n",
      "Número de escenarios para ENTRENAMIENTO: 400\n",
      "Índices originales usados para ENTRENAMIENTO (primeros 50):\n",
      "[1, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61]\n",
      "...\n",
      "------------------------------------------------------------\n",
      "Número de escenarios para VALIDACIÓN: 100\n",
      "Índices originales usados para VALIDACIÓN (primeros 50):\n",
      "[0, 2, 9, 11, 15, 18, 22, 30, 33, 39, 46, 55, 63, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 82, 84, 86, 90, 93, 101, 104, 124, 131, 148, 154, 155, 172, 173, 180, 182, 185, 193, 194, 204, 209, 211, 238, 262, 268, 277, 278]\n",
      "...\n",
      "============================================================\n",
      "\n",
      "Forma datos entrenamiento (Input): torch.Size([400, 74, 6])\n",
      "Forma datos validación (Input): torch.Size([100, 74, 6])\n",
      "Usando dispositivo: mps\n",
      "Input dim: 6, Output dim: 4\n",
      "\n",
      "============================================================\n",
      "--- INICIANDO OPTIMIZACIÓN CON OPTUNA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:37:06,102] A new study created in RDB with name: transformer_optimization_v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estudio Optuna 'transformer_optimization_v1' cargado/creado desde 'sqlite:///transformer_optimization_v1.db'.\n",
      "Número de trials ya completados: 0\n",
      "\n",
      "--- Optuna Trial 0 ---\n",
      "Params: d_model=128, nhead=8, layers=5, ff=256(2x), drop=0.056, lr=0.000853, bs=16, wd=0.0000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.00477, Val Loss: 1.02005\n",
      "    Epoch 02/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    Epoch 03/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    Epoch 04/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    Epoch 05/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    Epoch 06/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    Epoch 07/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    Epoch 08/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    --> Optuna trial early stopping at epoch 8. Val Loss: 1.02005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:37:20,399] Trial 0 finished with value: 1.0200546383857727 and parameters: {'d_model': 128, 'ff_multiplier': 2, 'nhead': 8, 'num_encoder_layers': 5, 'dropout': 0.05617534828874074, 'learning_rate': 0.000852632076949155, 'batch_size': 16, 'weight_decay': 1.6480446427978977e-06}. Best is trial 0 with value: 1.0200546383857727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 1 ---\n",
      "Params: d_model=64, nhead=16, layers=2, ff=128(2x), drop=0.204, lr=0.000115, bs=32, wd=0.0006245\n",
      "    Epoch 01/30, Train Loss: 1.02351, Val Loss: 1.03662\n",
      "    Epoch 02/30, Train Loss: 1.00141, Val Loss: 1.03238\n",
      "    Epoch 03/30, Train Loss: 0.99807, Val Loss: 1.03237\n",
      "    Epoch 04/30, Train Loss: 0.99716, Val Loss: 1.03238\n",
      "    Epoch 05/30, Train Loss: 0.99721, Val Loss: 1.03238\n",
      "    Epoch 06/30, Train Loss: 0.99767, Val Loss: 1.03238\n",
      "    Epoch 07/30, Train Loss: 0.99944, Val Loss: 1.03238\n",
      "    Epoch 08/30, Train Loss: 0.99933, Val Loss: 1.03238\n",
      "    Epoch 09/30, Train Loss: 0.99879, Val Loss: 1.03238\n",
      "    Epoch 10/30, Train Loss: 0.99850, Val Loss: 1.03238\n",
      "    --> Optuna trial early stopping at epoch 10. Val Loss: 1.03237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:37:29,384] Trial 1 finished with value: 1.0323684513568878 and parameters: {'d_model': 64, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 2, 'dropout': 0.20427033152408347, 'learning_rate': 0.00011538084020058666, 'batch_size': 32, 'weight_decay': 0.000624513957474307}. Best is trial 0 with value: 1.0200546383857727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 2 ---\n",
      "Params: d_model=64, nhead=8, layers=6, ff=256(4x), drop=0.128, lr=0.000167, bs=64, wd=0.0007557\n",
      "    Epoch 01/30, Train Loss: 1.04152, Val Loss: 1.01502\n",
      "    Epoch 02/30, Train Loss: 1.00104, Val Loss: 1.01505\n",
      "    Epoch 03/30, Train Loss: 0.99787, Val Loss: 1.01505\n",
      "    Epoch 04/30, Train Loss: 0.99809, Val Loss: 1.01505\n",
      "    Epoch 05/30, Train Loss: 0.99442, Val Loss: 1.01505\n",
      "    Epoch 06/30, Train Loss: 0.99474, Val Loss: 1.01505\n",
      "    Epoch 07/30, Train Loss: 0.99338, Val Loss: 1.01505\n",
      "    Epoch 08/30, Train Loss: 0.99355, Val Loss: 1.01505\n",
      "    --> Optuna trial early stopping at epoch 8. Val Loss: 1.01502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:37:39,736] Trial 2 finished with value: 1.0150229632854462 and parameters: {'d_model': 64, 'ff_multiplier': 4, 'nhead': 8, 'num_encoder_layers': 6, 'dropout': 0.12763399448000506, 'learning_rate': 0.00016728371068484117, 'batch_size': 64, 'weight_decay': 0.0007556810141274422}. Best is trial 2 with value: 1.0150229632854462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 3 ---\n",
      "Params: d_model=128, nhead=16, layers=3, ff=512(4x), drop=0.131, lr=0.000404, bs=64, wd=0.0001617\n",
      "    Epoch 01/30, Train Loss: 1.01231, Val Loss: 1.01505\n",
      "    Epoch 02/30, Train Loss: 1.00112, Val Loss: 1.01505\n",
      "    Epoch 03/30, Train Loss: 1.00066, Val Loss: 1.01505\n",
      "    Epoch 04/30, Train Loss: 1.00270, Val Loss: 1.01505\n",
      "    Epoch 05/30, Train Loss: 0.99768, Val Loss: 1.01505\n",
      "    Epoch 06/30, Train Loss: 0.99559, Val Loss: 1.01505\n",
      "    Epoch 07/30, Train Loss: 1.00571, Val Loss: 1.01505\n",
      "    Epoch 08/30, Train Loss: 0.99689, Val Loss: 1.01505\n",
      "    --> Optuna trial early stopping at epoch 8. Val Loss: 1.01505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:38:34,518] Trial 3 finished with value: 1.0150474607944489 and parameters: {'d_model': 128, 'ff_multiplier': 4, 'nhead': 16, 'num_encoder_layers': 3, 'dropout': 0.13140470953216876, 'learning_rate': 0.00040357092610848494, 'batch_size': 64, 'weight_decay': 0.00016172900811143125}. Best is trial 2 with value: 1.0150229632854462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 4 ---\n",
      "Params: d_model=128, nhead=2, layers=1, ff=256(2x), drop=0.158, lr=0.000009, bs=16, wd=0.0000018\n",
      "    Epoch 01/30, Train Loss: 1.16488, Val Loss: 1.13624\n",
      "    Epoch 02/30, Train Loss: 1.11600, Val Loss: 1.08969\n",
      "    Epoch 03/30, Train Loss: 1.07779, Val Loss: 1.05680\n",
      "    Epoch 04/30, Train Loss: 1.04964, Val Loss: 1.03658\n",
      "    Epoch 05/30, Train Loss: 1.02939, Val Loss: 1.02714\n",
      "    Epoch 06/30, Train Loss: 1.01921, Val Loss: 1.02314\n",
      "    Epoch 07/30, Train Loss: 1.01343, Val Loss: 1.02130\n",
      "    Epoch 08/30, Train Loss: 1.00885, Val Loss: 1.02050\n",
      "    Epoch 09/30, Train Loss: 1.00698, Val Loss: 1.02020\n",
      "    Epoch 10/30, Train Loss: 1.00431, Val Loss: 1.01997\n",
      "    Epoch 11/30, Train Loss: 1.00374, Val Loss: 1.01992\n",
      "    Epoch 12/30, Train Loss: 1.00306, Val Loss: 1.01996\n",
      "    Epoch 13/30, Train Loss: 1.00154, Val Loss: 1.01998\n",
      "    Epoch 14/30, Train Loss: 1.00149, Val Loss: 1.02001\n",
      "    Epoch 15/30, Train Loss: 1.00089, Val Loss: 1.02004\n",
      "    Epoch 16/30, Train Loss: 1.00088, Val Loss: 1.02005\n",
      "    Epoch 17/30, Train Loss: 1.00053, Val Loss: 1.02006\n",
      "    Epoch 18/30, Train Loss: 1.00031, Val Loss: 1.02006\n",
      "    --> Optuna trial early stopping at epoch 18. Val Loss: 1.01992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:38:50,321] Trial 4 finished with value: 1.0199229291507177 and parameters: {'d_model': 128, 'ff_multiplier': 2, 'nhead': 2, 'num_encoder_layers': 1, 'dropout': 0.15753971856328178, 'learning_rate': 9.238217564420603e-06, 'batch_size': 16, 'weight_decay': 1.7535949529764409e-06}. Best is trial 2 with value: 1.0150229632854462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 5 ---\n",
      "Params: d_model=128, nhead=8, layers=5, ff=256(2x), drop=0.198, lr=0.000080, bs=16, wd=0.0000351\n",
      "    Epoch 01/30, Train Loss: 1.04549, Val Loss: 1.02005\n",
      "    Epoch 02/30, Train Loss: 0.99795, Val Loss: 1.02005\n",
      "    Epoch 03/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    Epoch 04/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    Epoch 05/30, Train Loss: 0.99795, Val Loss: 1.02005\n",
      "    Epoch 06/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    Epoch 07/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    Epoch 08/30, Train Loss: 0.99794, Val Loss: 1.02005\n",
      "    --> Optuna trial early stopping at epoch 8. Val Loss: 1.02005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:39:06,325] Trial 5 finished with value: 1.0200546383857727 and parameters: {'d_model': 128, 'ff_multiplier': 2, 'nhead': 8, 'num_encoder_layers': 5, 'dropout': 0.19813867890931725, 'learning_rate': 7.976161234554842e-05, 'batch_size': 16, 'weight_decay': 3.512704726270847e-05}. Best is trial 2 with value: 1.0150229632854462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 6 ---\n",
      "Params: d_model=256, nhead=2, layers=1, ff=1024(4x), drop=0.329, lr=0.000362, bs=32, wd=0.0003717\n",
      "    Epoch 01/30, Train Loss: 1.05382, Val Loss: 1.03238\n",
      "    Epoch 02/30, Train Loss: 0.99937, Val Loss: 1.03238\n",
      "    Epoch 03/30, Train Loss: 1.00008, Val Loss: 1.03238\n",
      "    Epoch 04/30, Train Loss: 0.99739, Val Loss: 1.03238\n",
      "    Epoch 05/30, Train Loss: 0.99757, Val Loss: 1.03238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:39:15,129] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 06/30, Train Loss: 0.99839, Val Loss: 1.03238\n",
      "    --> Trial 6 podado en la época 6.\n",
      "\n",
      "--- Optuna Trial 7 ---\n",
      "Params: d_model=256, nhead=16, layers=1, ff=512(2x), drop=0.203, lr=0.000046, bs=128, wd=0.0000020\n",
      "    Epoch 01/30, Train Loss: 1.49333, Val Loss: 1.31284\n",
      "    Epoch 02/30, Train Loss: 1.27696, Val Loss: 1.11420\n",
      "    Epoch 03/30, Train Loss: 1.12144, Val Loss: 1.02855\n",
      "    Epoch 04/30, Train Loss: 1.05205, Val Loss: 1.01004\n",
      "    Epoch 05/30, Train Loss: 1.02102, Val Loss: 1.00837\n",
      "    Epoch 06/30, Train Loss: 1.01307, Val Loss: 1.00823\n",
      "    Epoch 07/30, Train Loss: 0.99768, Val Loss: 1.00823\n",
      "    Epoch 08/30, Train Loss: 0.99536, Val Loss: 1.00823\n",
      "    Epoch 09/30, Train Loss: 1.00483, Val Loss: 1.00823\n",
      "    Epoch 10/30, Train Loss: 0.99403, Val Loss: 1.00823\n",
      "    Epoch 11/30, Train Loss: 0.99568, Val Loss: 1.00823\n",
      "    Epoch 12/30, Train Loss: 1.00364, Val Loss: 1.00823\n",
      "    Epoch 13/30, Train Loss: 0.99116, Val Loss: 1.00823\n",
      "    Epoch 14/30, Train Loss: 0.99472, Val Loss: 1.00823\n",
      "    --> Optuna trial early stopping at epoch 14. Val Loss: 1.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:39:33,359] Trial 7 finished with value: 1.0082253217697144 and parameters: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 1, 'dropout': 0.2032241907732697, 'learning_rate': 4.565046893584959e-05, 'batch_size': 128, 'weight_decay': 1.9625093208439855e-06}. Best is trial 7 with value: 1.0082253217697144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 8 ---\n",
      "Params: d_model=128, nhead=4, layers=1, ff=256(2x), drop=0.233, lr=0.000072, bs=64, wd=0.0000004\n",
      "    Epoch 01/30, Train Loss: 1.13557, Val Loss: 1.07873\n",
      "    Epoch 02/30, Train Loss: 1.05909, Val Loss: 1.02786\n",
      "    Epoch 03/30, Train Loss: 1.02391, Val Loss: 1.01570\n",
      "    Epoch 04/30, Train Loss: 1.00546, Val Loss: 1.01487\n",
      "    Epoch 05/30, Train Loss: 1.00086, Val Loss: 1.01501\n",
      "    Epoch 06/30, Train Loss: 1.00318, Val Loss: 1.01504\n",
      "    Epoch 07/30, Train Loss: 1.00072, Val Loss: 1.01505\n",
      "    Epoch 08/30, Train Loss: 0.99852, Val Loss: 1.01505\n",
      "    Epoch 09/30, Train Loss: 0.99994, Val Loss: 1.01505\n",
      "    Epoch 10/30, Train Loss: 0.99901, Val Loss: 1.01505\n",
      "    --> Trial 8 podado en la época 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:39:41,686] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 9 ---\n",
      "Params: d_model=128, nhead=4, layers=4, ff=512(4x), drop=0.211, lr=0.000008, bs=16, wd=0.0000231\n",
      "    Epoch 01/30, Train Loss: 1.09064, Val Loss: 1.04025\n",
      "    Epoch 02/30, Train Loss: 1.01879, Val Loss: 1.02117\n",
      "    Epoch 03/30, Train Loss: 1.00401, Val Loss: 1.02017\n",
      "    Epoch 04/30, Train Loss: 1.00071, Val Loss: 1.02010\n",
      "    Epoch 05/30, Train Loss: 0.99939, Val Loss: 1.02010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:39:53,659] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 06/30, Train Loss: 0.99915, Val Loss: 1.02008\n",
      "    --> Trial 9 podado en la época 6.\n",
      "\n",
      "--- Optuna Trial 10 ---\n",
      "Params: d_model=256, nhead=16, layers=3, ff=512(2x), drop=0.287, lr=0.000025, bs=128, wd=0.0000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(73754) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(73755) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.25475, Val Loss: 1.12715\n",
      "    Epoch 02/30, Train Loss: 1.12791, Val Loss: 1.02880\n",
      "    Epoch 03/30, Train Loss: 1.04638, Val Loss: 1.00897\n",
      "    Epoch 04/30, Train Loss: 1.01009, Val Loss: 1.00822\n",
      "    Epoch 05/30, Train Loss: 1.01559, Val Loss: 1.00823\n",
      "    Epoch 06/30, Train Loss: 1.00128, Val Loss: 1.00823\n",
      "    Epoch 07/30, Train Loss: 0.99595, Val Loss: 1.00823\n",
      "    Epoch 08/30, Train Loss: 0.99875, Val Loss: 1.00823\n",
      "    Epoch 09/30, Train Loss: 1.00159, Val Loss: 1.00823\n",
      "    Epoch 10/30, Train Loss: 0.99359, Val Loss: 1.00823\n",
      "    Epoch 11/30, Train Loss: 0.99618, Val Loss: 1.00823\n",
      "    --> Optuna trial early stopping at epoch 11. Val Loss: 1.00822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:40:18,828] Trial 10 finished with value: 1.0082236528396606 and parameters: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 3, 'dropout': 0.28678589490492357, 'learning_rate': 2.457981884685407e-05, 'batch_size': 128, 'weight_decay': 1.1941063844170234e-07}. Best is trial 10 with value: 1.0082236528396606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 11 ---\n",
      "Params: d_model=256, nhead=16, layers=3, ff=512(2x), drop=0.304, lr=0.000024, bs=128, wd=0.0000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(74019) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(74020) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(74093) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(74094) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.39892, Val Loss: 1.18898\n",
      "    Epoch 02/30, Train Loss: 1.21212, Val Loss: 1.05288\n",
      "    Epoch 03/30, Train Loss: 1.09658, Val Loss: 1.01429\n",
      "    Epoch 04/30, Train Loss: 1.03708, Val Loss: 1.00842\n",
      "    Epoch 05/30, Train Loss: 1.02193, Val Loss: 1.00822\n",
      "    Epoch 06/30, Train Loss: 1.00527, Val Loss: 1.00823\n",
      "    Epoch 07/30, Train Loss: 0.99829, Val Loss: 1.00823\n",
      "    Epoch 08/30, Train Loss: 1.00080, Val Loss: 1.00823\n",
      "    Epoch 09/30, Train Loss: 0.98856, Val Loss: 1.00823\n",
      "    Epoch 10/30, Train Loss: 0.99561, Val Loss: 1.00823\n",
      "    Epoch 11/30, Train Loss: 0.99862, Val Loss: 1.00823\n",
      "    Epoch 12/30, Train Loss: 0.99990, Val Loss: 1.00823\n",
      "    --> Optuna trial early stopping at epoch 12. Val Loss: 1.00822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:40:40,264] Trial 11 finished with value: 1.008224606513977 and parameters: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 3, 'dropout': 0.30381104231125405, 'learning_rate': 2.3519033967501944e-05, 'batch_size': 128, 'weight_decay': 1.1315208010515518e-07}. Best is trial 10 with value: 1.0082236528396606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 12 ---\n",
      "Params: d_model=256, nhead=16, layers=3, ff=512(2x), drop=0.321, lr=0.000028, bs=128, wd=0.0000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(74340) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(74341) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(74413) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(74414) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.25305, Val Loss: 1.06629\n",
      "    Epoch 02/30, Train Loss: 1.11517, Val Loss: 1.01648\n",
      "    Epoch 03/30, Train Loss: 1.04839, Val Loss: 1.00855\n",
      "    Epoch 04/30, Train Loss: 1.01645, Val Loss: 1.00824\n",
      "    Epoch 05/30, Train Loss: 1.00707, Val Loss: 1.00823\n",
      "    Epoch 06/30, Train Loss: 1.00045, Val Loss: 1.00823\n",
      "    Epoch 07/30, Train Loss: 0.99867, Val Loss: 1.00823\n",
      "    Epoch 08/30, Train Loss: 0.99910, Val Loss: 1.00823\n",
      "    Epoch 09/30, Train Loss: 0.99684, Val Loss: 1.00823\n",
      "    Epoch 10/30, Train Loss: 1.00843, Val Loss: 1.00823\n",
      "    Epoch 11/30, Train Loss: 0.99246, Val Loss: 1.00823\n",
      "    Epoch 12/30, Train Loss: 1.00292, Val Loss: 1.00823\n",
      "    --> Optuna trial early stopping at epoch 12. Val Loss: 1.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:41:01,151] Trial 12 finished with value: 1.0082253217697144 and parameters: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 3, 'dropout': 0.32061418767892724, 'learning_rate': 2.750210473326018e-05, 'batch_size': 128, 'weight_decay': 1.5199561745327618e-07}. Best is trial 10 with value: 1.0082236528396606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 13 ---\n",
      "Params: d_model=256, nhead=16, layers=4, ff=512(2x), drop=0.270, lr=0.000017, bs=128, wd=0.0000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(74654) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(74655) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(74727) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(74728) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.62166, Val Loss: 1.46128\n",
      "    Epoch 02/30, Train Loss: 1.36894, Val Loss: 1.21220\n",
      "    Epoch 03/30, Train Loss: 1.20149, Val Loss: 1.08139\n",
      "    Epoch 04/30, Train Loss: 1.10181, Val Loss: 1.02705\n",
      "    Epoch 05/30, Train Loss: 1.03096, Val Loss: 1.01147\n",
      "    Epoch 06/30, Train Loss: 1.01810, Val Loss: 1.00864\n",
      "    Epoch 07/30, Train Loss: 1.00731, Val Loss: 1.00823\n",
      "    Epoch 08/30, Train Loss: 1.00212, Val Loss: 1.00823\n",
      "    Epoch 09/30, Train Loss: 0.99996, Val Loss: 1.00823\n",
      "    Epoch 10/30, Train Loss: 0.99932, Val Loss: 1.00823\n",
      "    Epoch 11/30, Train Loss: 0.99966, Val Loss: 1.00823\n",
      "    Epoch 12/30, Train Loss: 0.99151, Val Loss: 1.00823\n",
      "    Epoch 13/30, Train Loss: 0.99676, Val Loss: 1.00823\n",
      "    Epoch 14/30, Train Loss: 0.99359, Val Loss: 1.00823\n",
      "    Epoch 15/30, Train Loss: 1.00351, Val Loss: 1.00823\n",
      "    --> Optuna trial early stopping at epoch 15. Val Loss: 1.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:41:34,261] Trial 13 finished with value: 1.0082253217697144 and parameters: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 4, 'dropout': 0.2699284325342433, 'learning_rate': 1.677257879303403e-05, 'batch_size': 128, 'weight_decay': 1.0230463944244417e-07}. Best is trial 10 with value: 1.0082236528396606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 14 ---\n",
      "Params: d_model=256, nhead=16, layers=3, ff=512(2x), drop=0.276, lr=0.000021, bs=128, wd=0.0000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(75131) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75132) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75169) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75170) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.33683, Val Loss: 1.19538\n",
      "    Epoch 02/30, Train Loss: 1.17289, Val Loss: 1.06475\n",
      "    Epoch 03/30, Train Loss: 1.09348, Val Loss: 1.01714\n",
      "    Epoch 04/30, Train Loss: 1.03684, Val Loss: 1.00899\n",
      "    Epoch 05/30, Train Loss: 1.01223, Val Loss: 1.00824\n",
      "    Epoch 06/30, Train Loss: 1.01370, Val Loss: 1.00823\n",
      "    Epoch 07/30, Train Loss: 1.00126, Val Loss: 1.00823\n",
      "    Epoch 08/30, Train Loss: 0.99505, Val Loss: 1.00823\n",
      "    Epoch 09/30, Train Loss: 0.99555, Val Loss: 1.00823\n",
      "    Epoch 10/30, Train Loss: 0.99743, Val Loss: 1.00823\n",
      "    Epoch 11/30, Train Loss: 0.99583, Val Loss: 1.00823\n",
      "    Epoch 12/30, Train Loss: 1.00569, Val Loss: 1.00823\n",
      "    Epoch 13/30, Train Loss: 0.99960, Val Loss: 1.00823\n",
      "    --> Optuna trial early stopping at epoch 13. Val Loss: 1.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:41:57,047] Trial 14 finished with value: 1.0082250833511353 and parameters: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 3, 'dropout': 0.2763422375654154, 'learning_rate': 2.0937038683110453e-05, 'batch_size': 128, 'weight_decay': 5.529598542572281e-07}. Best is trial 10 with value: 1.0082236528396606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 15 ---\n",
      "Params: d_model=256, nhead=16, layers=2, ff=512(2x), drop=0.284, lr=0.000036, bs=128, wd=0.0000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(75479) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75480) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75516) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75517) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.26051, Val Loss: 1.10661\n",
      "    Epoch 02/30, Train Loss: 1.11882, Val Loss: 1.02112\n",
      "    Epoch 03/30, Train Loss: 1.04279, Val Loss: 1.00872\n",
      "    Epoch 04/30, Train Loss: 1.00630, Val Loss: 1.00823\n",
      "    Epoch 05/30, Train Loss: 0.99869, Val Loss: 1.00823\n",
      "    Epoch 06/30, Train Loss: 1.00412, Val Loss: 1.00823\n",
      "    Epoch 07/30, Train Loss: 0.99175, Val Loss: 1.00823\n",
      "    Epoch 08/30, Train Loss: 1.00018, Val Loss: 1.00823\n",
      "    Epoch 09/30, Train Loss: 1.00665, Val Loss: 1.00823\n",
      "    Epoch 10/30, Train Loss: 1.00019, Val Loss: 1.00823\n",
      "    Epoch 11/30, Train Loss: 0.99761, Val Loss: 1.00823\n",
      "    Epoch 12/30, Train Loss: 1.00075, Val Loss: 1.00823\n",
      "    --> Optuna trial early stopping at epoch 12. Val Loss: 1.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:42:13,447] Trial 15 finished with value: 1.0082253217697144 and parameters: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 2, 'dropout': 0.28393247612858, 'learning_rate': 3.550901209356492e-05, 'batch_size': 128, 'weight_decay': 4.6369021127463605e-07}. Best is trial 10 with value: 1.0082236528396606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 16 ---\n",
      "Params: d_model=256, nhead=16, layers=2, ff=512(2x), drop=0.350, lr=0.000013, bs=128, wd=0.0000047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(75743) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75744) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75781) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75782) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.45674, Val Loss: 1.31247\n",
      "    Epoch 02/30, Train Loss: 1.36122, Val Loss: 1.22316\n",
      "    Epoch 03/30, Train Loss: 1.30350, Val Loss: 1.15427\n",
      "    Epoch 04/30, Train Loss: 1.24981, Val Loss: 1.10248\n",
      "    Epoch 05/30, Train Loss: 1.20424, Val Loss: 1.06514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:42:22,765] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 06/30, Train Loss: 1.15700, Val Loss: 1.03961\n",
      "    --> Trial 16 podado en la época 6.\n",
      "\n",
      "--- Optuna Trial 17 ---\n",
      "Params: d_model=256, nhead=4, layers=4, ff=512(2x), drop=0.297, lr=0.000006, bs=128, wd=0.0000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(75883) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75884) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75953) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(75954) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.35726, Val Loss: 1.27004\n",
      "    Epoch 02/30, Train Loss: 1.28066, Val Loss: 1.19309\n",
      "    Epoch 03/30, Train Loss: 1.23123, Val Loss: 1.13294\n",
      "    Epoch 04/30, Train Loss: 1.17018, Val Loss: 1.08741\n",
      "    Epoch 05/30, Train Loss: 1.14015, Val Loss: 1.05472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:42:40,052] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 06/30, Train Loss: 1.10255, Val Loss: 1.03321\n",
      "    --> Trial 17 podado en la época 6.\n",
      "\n",
      "--- Optuna Trial 18 ---\n",
      "Params: d_model=64, nhead=2, layers=3, ff=256(4x), drop=0.245, lr=0.000046, bs=128, wd=0.0000085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(76459) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(76460) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(76630) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(76659) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.20158, Val Loss: 1.19575\n",
      "    Epoch 02/30, Train Loss: 1.15487, Val Loss: 1.14598\n",
      "    Epoch 03/30, Train Loss: 1.10843, Val Loss: 1.10557\n",
      "    Epoch 04/30, Train Loss: 1.08672, Val Loss: 1.07390\n",
      "    Epoch 05/30, Train Loss: 1.06042, Val Loss: 1.04997\n",
      "    Epoch 06/30, Train Loss: 1.04277, Val Loss: 1.03306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:43:52,359] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    --> Trial 18 podado en la época 6.\n",
      "\n",
      "--- Optuna Trial 19 ---\n",
      "Params: d_model=256, nhead=16, layers=5, ff=512(2x), drop=0.309, lr=0.000012, bs=32, wd=0.0000009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(76931) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(76933) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(76999) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(77000) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.30709, Val Loss: 1.03695\n",
      "    Epoch 02/30, Train Loss: 1.02183, Val Loss: 1.03238\n",
      "    Epoch 03/30, Train Loss: 0.99861, Val Loss: 1.03238\n",
      "    Epoch 04/30, Train Loss: 0.99858, Val Loss: 1.03238\n",
      "    Epoch 05/30, Train Loss: 0.99811, Val Loss: 1.03238\n",
      "    Epoch 06/30, Train Loss: 0.99782, Val Loss: 1.03238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:44:26,524] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    --> Trial 19 podado en la época 6.\n",
      "\n",
      "--- Optuna Trial 20 ---\n",
      "Params: d_model=256, nhead=16, layers=2, ff=512(2x), drop=0.253, lr=0.000025, bs=128, wd=0.0000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(77563) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(77564) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(77729) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(77730) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.45183, Val Loss: 1.33635\n",
      "    Epoch 02/30, Train Loss: 1.30054, Val Loss: 1.16825\n",
      "    Epoch 03/30, Train Loss: 1.18060, Val Loss: 1.06931\n",
      "    Epoch 04/30, Train Loss: 1.09826, Val Loss: 1.02399\n",
      "    Epoch 05/30, Train Loss: 1.05581, Val Loss: 1.01090\n",
      "    Epoch 06/30, Train Loss: 1.01958, Val Loss: 1.00837\n",
      "    Epoch 07/30, Train Loss: 1.01365, Val Loss: 1.00821\n",
      "    Epoch 08/30, Train Loss: 1.00501, Val Loss: 1.00823\n",
      "    Epoch 09/30, Train Loss: 1.00733, Val Loss: 1.00823\n",
      "    Epoch 10/30, Train Loss: 0.99121, Val Loss: 1.00823\n",
      "    Epoch 11/30, Train Loss: 0.99997, Val Loss: 1.00823\n",
      "    Epoch 12/30, Train Loss: 1.01581, Val Loss: 1.00823\n",
      "    Epoch 13/30, Train Loss: 0.99852, Val Loss: 1.00823\n",
      "    Epoch 14/30, Train Loss: 1.00190, Val Loss: 1.00823\n",
      "    --> Optuna trial early stopping at epoch 14. Val Loss: 1.00821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:45:14,109] Trial 20 finished with value: 1.0082131624221802 and parameters: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 2, 'dropout': 0.2528329926341195, 'learning_rate': 2.4879974687118915e-05, 'batch_size': 128, 'weight_decay': 1.1333479648867827e-07}. Best is trial 20 with value: 1.0082131624221802.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 21 ---\n",
      "Params: d_model=256, nhead=16, layers=2, ff=512(2x), drop=0.248, lr=0.000024, bs=128, wd=0.0000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(77933) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(77934) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(77999) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78000) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.44560, Val Loss: 1.32426\n",
      "    Epoch 02/30, Train Loss: 1.26863, Val Loss: 1.15051\n",
      "    Epoch 03/30, Train Loss: 1.16080, Val Loss: 1.05521\n",
      "    Epoch 04/30, Train Loss: 1.08882, Val Loss: 1.01758\n",
      "    Epoch 05/30, Train Loss: 1.03695, Val Loss: 1.00912\n",
      "    Epoch 06/30, Train Loss: 1.02116, Val Loss: 1.00827\n",
      "    Epoch 07/30, Train Loss: 1.00937, Val Loss: 1.00823\n",
      "    Epoch 08/30, Train Loss: 0.99665, Val Loss: 1.00823\n",
      "    Epoch 09/30, Train Loss: 1.00262, Val Loss: 1.00823\n",
      "    Epoch 10/30, Train Loss: 0.99528, Val Loss: 1.00823\n",
      "    Epoch 11/30, Train Loss: 1.00443, Val Loss: 1.00823\n",
      "    Epoch 12/30, Train Loss: 0.99938, Val Loss: 1.00823\n",
      "    Epoch 13/30, Train Loss: 0.99994, Val Loss: 1.00823\n",
      "    Epoch 14/30, Train Loss: 1.00552, Val Loss: 1.00823\n",
      "    --> Optuna trial early stopping at epoch 14. Val Loss: 1.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:45:29,336] Trial 21 finished with value: 1.0082250833511353 and parameters: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 2, 'dropout': 0.24775512750979153, 'learning_rate': 2.4125632692153175e-05, 'batch_size': 128, 'weight_decay': 2.0544243016563943e-07}. Best is trial 20 with value: 1.0082131624221802.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 22 ---\n",
      "Params: d_model=256, nhead=16, layers=2, ff=512(2x), drop=0.259, lr=0.000042, bs=128, wd=0.0000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(78163) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78164) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78197) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78198) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.29907, Val Loss: 1.09486\n",
      "    Epoch 02/30, Train Loss: 1.12409, Val Loss: 1.01411\n",
      "    Epoch 03/30, Train Loss: 1.02696, Val Loss: 1.00834\n",
      "    Epoch 04/30, Train Loss: 1.00177, Val Loss: 1.00823\n",
      "    Epoch 05/30, Train Loss: 0.99446, Val Loss: 1.00823\n",
      "    Epoch 06/30, Train Loss: 1.00408, Val Loss: 1.00823\n",
      "    Epoch 07/30, Train Loss: 0.99916, Val Loss: 1.00823\n",
      "    Epoch 08/30, Train Loss: 0.99320, Val Loss: 1.00823\n",
      "    Epoch 09/30, Train Loss: 1.00181, Val Loss: 1.00823\n",
      "    Epoch 10/30, Train Loss: 0.99930, Val Loss: 1.00823\n",
      "    Epoch 11/30, Train Loss: 1.00495, Val Loss: 1.00823\n",
      "    Epoch 12/30, Train Loss: 1.00627, Val Loss: 1.00823\n",
      "    --> Optuna trial early stopping at epoch 12. Val Loss: 1.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:45:44,773] Trial 22 finished with value: 1.0082253217697144 and parameters: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 2, 'dropout': 0.2591055456592846, 'learning_rate': 4.181982807762219e-05, 'batch_size': 128, 'weight_decay': 1.0023022534034042e-07}. Best is trial 20 with value: 1.0082131624221802.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 23 ---\n",
      "Params: d_model=256, nhead=16, layers=3, ff=512(2x), drop=0.299, lr=0.000018, bs=128, wd=0.0000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(78391) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78392) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78425) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78426) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.34360, Val Loss: 1.28956\n",
      "    Epoch 02/30, Train Loss: 1.19769, Val Loss: 1.13548\n",
      "    Epoch 03/30, Train Loss: 1.11791, Val Loss: 1.05276\n",
      "    Epoch 04/30, Train Loss: 1.05851, Val Loss: 1.01869\n",
      "    Epoch 05/30, Train Loss: 1.02304, Val Loss: 1.00942\n",
      "    Epoch 06/30, Train Loss: 1.01696, Val Loss: 1.00829\n",
      "    Epoch 07/30, Train Loss: 1.01264, Val Loss: 1.00821\n",
      "    Epoch 08/30, Train Loss: 0.99532, Val Loss: 1.00823\n",
      "    Epoch 09/30, Train Loss: 0.99980, Val Loss: 1.00823\n",
      "    Epoch 10/30, Train Loss: 0.99941, Val Loss: 1.00823\n",
      "    Epoch 11/30, Train Loss: 0.99168, Val Loss: 1.00823\n",
      "    Epoch 12/30, Train Loss: 1.00276, Val Loss: 1.00823\n",
      "    Epoch 13/30, Train Loss: 0.99980, Val Loss: 1.00823\n",
      "    Epoch 14/30, Train Loss: 0.99327, Val Loss: 1.00823\n",
      "    --> Optuna trial early stopping at epoch 14. Val Loss: 1.00821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:46:08,505] Trial 23 finished with value: 1.0082108974456787 and parameters: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 3, 'dropout': 0.29867226031868743, 'learning_rate': 1.7633861657015756e-05, 'batch_size': 128, 'weight_decay': 2.9841239840264177e-07}. Best is trial 23 with value: 1.0082108974456787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Trial 24 ---\n",
      "Params: d_model=256, nhead=16, layers=4, ff=512(2x), drop=0.341, lr=0.000006, bs=128, wd=0.0000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(78715) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78716) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78777) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78778) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 01/30, Train Loss: 1.44805, Val Loss: 1.46518\n",
      "    Epoch 02/30, Train Loss: 1.38513, Val Loss: 1.36717\n",
      "    Epoch 03/30, Train Loss: 1.30759, Val Loss: 1.28447\n",
      "    Epoch 04/30, Train Loss: 1.26414, Val Loss: 1.21560\n",
      "    Epoch 05/30, Train Loss: 1.22201, Val Loss: 1.15942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 02:46:23,838] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 06/30, Train Loss: 1.16946, Val Loss: 1.11433\n",
      "    --> Trial 24 podado en la época 6.\n",
      "\n",
      "============================================================\n",
      "--- OPTIMIZACIÓN FINALIZADA ---\n",
      "Mejor Valor (Val Loss): 1.00821\n",
      "Mejores Hiperparámetros encontrados:\n",
      "{'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 3, 'dropout': 0.29867226031868743, 'learning_rate': 1.7633861657015756e-05, 'batch_size': 128, 'weight_decay': 2.9841239840264177e-07}\n",
      "\n",
      "============================================================\n",
      "--- INICIANDO ENTRENAMIENTO FINAL ---\n",
      "Usando parámetros: {'d_model': 256, 'ff_multiplier': 2, 'nhead': 16, 'num_encoder_layers': 3, 'dropout': 0.29867226031868743, 'learning_rate': 1.7633861657015756e-05, 'batch_size': 128, 'weight_decay': 2.9841239840264177e-07, 'calculated_dim_feedforward': 512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(78943) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78944) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78977) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(78978) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/150, Train Loss: 1.43308, Val Loss: 1.27109, LR: 0.000018, Time: 5.20s\n",
      "    --> Modelo guardado en best_transformer_model_relu.pth (Val Loss: 1.27109)\n",
      "Epoch 002/150, Train Loss: 1.28258, Val Loss: 1.11978, LR: 0.000018, Time: 1.55s\n",
      "    --> Modelo guardado en best_transformer_model_relu.pth (Val Loss: 1.11978)\n",
      "Epoch 003/150, Train Loss: 1.16825, Val Loss: 1.04327, LR: 0.000018, Time: 1.45s\n",
      "    --> Modelo guardado en best_transformer_model_relu.pth (Val Loss: 1.04327)\n",
      "Epoch 004/150, Train Loss: 1.08491, Val Loss: 1.01537, LR: 0.000018, Time: 1.32s\n",
      "    --> Modelo guardado en best_transformer_model_relu.pth (Val Loss: 1.01537)\n",
      "Epoch 005/150, Train Loss: 1.05102, Val Loss: 1.00914, LR: 0.000018, Time: 1.27s\n",
      "    --> Modelo guardado en best_transformer_model_relu.pth (Val Loss: 1.00914)\n",
      "Epoch 006/150, Train Loss: 1.01522, Val Loss: 1.00835, LR: 0.000018, Time: 1.09s\n",
      "    --> Modelo guardado en best_transformer_model_relu.pth (Val Loss: 1.00835)\n",
      "Epoch 007/150, Train Loss: 1.01349, Val Loss: 1.00823, LR: 0.000018, Time: 1.08s\n",
      "    --> Modelo guardado en best_transformer_model_relu.pth (Val Loss: 1.00823)\n",
      "Epoch 008/150, Train Loss: 1.00919, Val Loss: 1.00823, LR: 0.000018, Time: 1.10s\n",
      "    --> Modelo guardado en best_transformer_model_relu.pth (Val Loss: 1.00823)\n",
      "Epoch 009/150, Train Loss: 1.00585, Val Loss: 1.00823, LR: 0.000018, Time: 1.30s\n",
      "Epoch 010/150, Train Loss: 0.99863, Val Loss: 1.00823, LR: 0.000018, Time: 1.33s\n",
      "Epoch 011/150, Train Loss: 0.99350, Val Loss: 1.00823, LR: 0.000018, Time: 1.27s\n",
      "Epoch 012/150, Train Loss: 1.00174, Val Loss: 1.00823, LR: 0.000018, Time: 1.29s\n",
      "Epoch 013/150, Train Loss: 0.99788, Val Loss: 1.00823, LR: 0.000018, Time: 1.30s\n",
      "Epoch 014/150, Train Loss: 0.99244, Val Loss: 1.00823, LR: 0.000018, Time: 1.26s\n",
      "Epoch 015/150, Train Loss: 0.99663, Val Loss: 1.00823, LR: 0.000018, Time: 1.19s\n",
      "Epoch 016/150, Train Loss: 0.99603, Val Loss: 1.00823, LR: 0.000018, Time: 1.17s\n",
      "Epoch 017/150, Train Loss: 0.99631, Val Loss: 1.00823, LR: 0.000018, Time: 1.43s\n",
      "Epoch 018/150, Train Loss: 0.99657, Val Loss: 1.00823, LR: 0.000018, Time: 1.24s\n",
      "Epoch 019/150, Train Loss: 1.00851, Val Loss: 1.00823, LR: 0.000009, Time: 1.37s\n",
      "Epoch 020/150, Train Loss: 1.00346, Val Loss: 1.00823, LR: 0.000009, Time: 1.25s\n",
      "Epoch 021/150, Train Loss: 1.00139, Val Loss: 1.00823, LR: 0.000009, Time: 1.63s\n",
      "Epoch 022/150, Train Loss: 1.00000, Val Loss: 1.00823, LR: 0.000009, Time: 1.38s\n",
      "Epoch 023/150, Train Loss: 1.00183, Val Loss: 1.00823, LR: 0.000009, Time: 1.37s\n",
      "    --> Early stopping activado tras 15 épocas sin mejora.\n",
      "Entrenamiento finalizado. Mejor Val Loss: 1.00823\n",
      "Mejor modelo cargado desde best_transformer_model_relu.pth\n",
      "\n",
      "============================================================\n",
      "--- SCRIPT DE ENTRENAMIENTO FINALIZADO ---\n",
      "Modelo final (con ReLU) entrenado. Mejor Loss de Validación: 1.00823\n",
      "Modelo guardado como 'best_transformer_model_relu.pth'.\n",
      "Los scalers (scaler_input, scaler_target) son necesarios para usar el modelo en datos nuevos.\n",
      "Los índices de entrenamiento/validación están en 'train_idx' y 'val_idx'.\n",
      "\n",
      "============================================================\n",
      "--- PRUEBA CON UN ESCENARIO ESPECÍFICO ---\n",
      "Se probará con el escenario de índice original: 0 (pertenece al conjunto de validación)\n",
      "Forma de la entrada original del escenario: torch.Size([74, 6])\n",
      "Predicción realizada en 1.4881 segundos.\n",
      "\n",
      "Predicción para el escenario 0 (Desnormalizada):\n",
      "Forma: (74, 4)\n",
      "Primeros 5 pasos:\n",
      " [[3.9714437 4.013006  4.0167575 3.9970672]\n",
      " [3.9714437 4.013006  4.0167575 3.9970672]\n",
      " [3.9714437 4.013006  4.0167575 3.9970672]\n",
      " [3.9714437 4.013006  4.0167575 3.9970672]\n",
      " [3.9714437 4.013006  4.0167575 3.9970672]]\n",
      "\n",
      "Valor Real para el escenario 0 (Original):\n",
      "Forma: (74, 4)\n",
      "Primeros 5 pasos:\n",
      " [[10.739031   1.9509555  5.9624233  1.2299176]\n",
      " [ 1.0115863  4.9236174  3.1815815  7.994131 ]\n",
      " [ 9.688989   9.712443   3.1813238  5.280407 ]\n",
      " [ 6.613281   3.8063807  1.4643131 17.902504 ]\n",
      " [ 2.7434456  2.083682   3.997959   6.692013 ]]\n",
      "\n",
      "Error Absoluto Medio (MAE) para este escenario: 2.47180\n",
      "Raíz del Error Cuadrático Medio (RMSE) para este escenario: 3.10012\n",
      "\n",
      "Confirmado: No hay valores < 0 en la predicción desnormalizada final.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # Importado para F.relu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import math\n",
    "import time # Para medir tiempo\n",
    "import traceback # Para imprimir errores detallados\n",
    "\n",
    "# --- 1. Carga y Preprocesamiento de Datos ---\n",
    "# ######################################################################### #\n",
    "# ############# ¡¡¡IMPORTANTE!!! ############# #\n",
    "# REEMPLAZA ESTA SECCIÓN CON TU CÓDIGO REAL PARA CARGAR Y PREPARAR #\n",
    "# 'input_tensor' y 'target_tensor' #\n",
    "# Deben tener la forma: (num_escenarios, secuencia_len, num_features) #\n",
    "# Y ser tensores de PyTorch. #\n",
    "# ######################################################################### #\n",
    "print(\"Cargando y preprocesando datos...\")\n",
    "# Ejemplo Placeholder (DEBES REEMPLAZAR ESTO):\n",
    "try:\n",
    "    # Intenta cargar desde archivos si ya los tienes guardados\n",
    "    input_tensor = torch.load('input_tensor.pt')\n",
    "    target_tensor = torch.load('target_tensor.pt')\n",
    "    print(\"Tensores cargados desde archivos .pt\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Archivos .pt no encontrados, generando datos de ejemplo...\")\n",
    "    # Generar datos de ejemplo si no se encuentran archivos\n",
    "    num_escenarios = 500 # Reducido para ejemplo rápido\n",
    "    secuencia_len = 74   # Número de pares de relés\n",
    "    input_features = 6\n",
    "    output_features = 4\n",
    "    input_tensor = torch.rand(num_escenarios, secuencia_len, input_features, dtype=torch.float32)\n",
    "    # Asegurar que los datos objetivo de ejemplo sean no negativos\n",
    "    target_tensor = torch.abs(torch.randn(num_escenarios, secuencia_len, output_features, dtype=torch.float32)) * 5\n",
    "    # Guardar para la próxima vez (opcional)\n",
    "    # torch.save(input_tensor, 'input_tensor.pt')\n",
    "    # torch.save(target_tensor, 'target_tensor.pt')\n",
    "    print(\"Datos de ejemplo generados.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error al cargar/generar datos: {e}. Saliendo.\")\n",
    "     exit()\n",
    "\n",
    "# Asegurar que los tensores son float32\n",
    "input_tensor = input_tensor.float()\n",
    "target_tensor = target_tensor.float()\n",
    "\n",
    "print(f\"Forma Input Tensor Original: {input_tensor.shape}\")\n",
    "print(f\"Forma Target Tensor Original: {target_tensor.shape}\")\n",
    "# ######################################################################### #\n",
    "# ############# FIN DE LA SECCIÓN A REEMPLAZAR ############# #\n",
    "# ######################################################################### #\n",
    "\n",
    "\n",
    "# --- 2. Normalización ---\n",
    "print(\"Normalizando datos...\")\n",
    "# Guardar scalers para uso posterior\n",
    "scaler_input = StandardScaler()\n",
    "scaler_target = StandardScaler()\n",
    "\n",
    "try:\n",
    "    # Aplanar para ajustar los scalers\n",
    "    input_np_original = input_tensor.numpy().reshape(-1, input_tensor.shape[-1])\n",
    "    target_np_original = target_tensor.numpy().reshape(-1, target_tensor.shape[-1])\n",
    "\n",
    "    # Validar que no haya NaNs antes de escalar\n",
    "    if np.isnan(input_np_original).any() or np.isinf(input_np_original).any():\n",
    "        raise ValueError(\"Datos de entrada originales contienen NaNs o Infinitos.\")\n",
    "    if np.isnan(target_np_original).any() or np.isinf(target_np_original).any():\n",
    "         raise ValueError(\"Datos objetivo originales contienen NaNs o Infinitos.\")\n",
    "\n",
    "    # Ajustar y transformar\n",
    "    input_normalized = scaler_input.fit_transform(input_np_original)\n",
    "    target_normalized = scaler_target.fit_transform(target_np_original)\n",
    "\n",
    "    # Validar que no haya NaNs después de escalar\n",
    "    if np.isnan(input_normalized).any() or np.isinf(input_normalized).any():\n",
    "        raise ValueError(\"Datos de entrada contienen NaNs/Inf DESPUÉS de normalizar.\")\n",
    "    if np.isnan(target_normalized).any() or np.isinf(target_normalized).any():\n",
    "        raise ValueError(\"Datos objetivo contienen NaNs/Inf DESPUÉS de normalizar.\")\n",
    "\n",
    "    # Restaurar forma original\n",
    "    input_tensor_normalized = torch.tensor(input_normalized, dtype=torch.float32).reshape(input_tensor.shape)\n",
    "    target_tensor_normalized = torch.tensor(target_normalized, dtype=torch.float32).reshape(target_tensor.shape)\n",
    "    print(\"Datos normalizados correctamente.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la normalización: {e}\")\n",
    "    traceback.print_exc()\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 3. División Entrenamiento / Validación e Identificación ---\n",
    "print(\"Dividiendo datos...\")\n",
    "num_total_escenarios = input_tensor_normalized.shape[0]\n",
    "indices = list(range(num_total_escenarios)) # Usar lista para train_test_split\n",
    "test_split_percentage = 0.2\n",
    "random_seed = 42\n",
    "\n",
    "try:\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=test_split_percentage, random_state=random_seed, shuffle=True)\n",
    "except ValueError as e:\n",
    "     print(f\"Error en train_test_split: {e}. ¿Hay suficientes datos?\")\n",
    "     exit()\n",
    "\n",
    "# Convertir a listas y ordenar para facilitar visualización/manejo\n",
    "train_idx = sorted(list(train_idx))\n",
    "val_idx = sorted(list(val_idx))\n",
    "\n",
    "# --- Impresión de detalles de la división ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- DETALLES DE LA DIVISIÓN DE DATOS ---\")\n",
    "print(f\"Número total de escenarios originales: {num_total_escenarios}\")\n",
    "print(f\"Porcentaje para validación (test_size): {test_split_percentage * 100:.1f}%\")\n",
    "print(f\"Semilla aleatoria (random_state): {random_seed}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Número de escenarios para ENTRENAMIENTO: {len(train_idx)}\")\n",
    "print(f\"Índices originales usados para ENTRENAMIENTO (primeros 50):\")\n",
    "print(train_idx[:50])\n",
    "if len(train_idx) > 50: print(\"...\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Número de escenarios para VALIDACIÓN: {len(val_idx)}\")\n",
    "print(f\"Índices originales usados para VALIDACIÓN (primeros 50):\")\n",
    "print(val_idx[:50])\n",
    "if len(val_idx) > 50: print(\"...\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "# --- Fin Impresión ---\n",
    "\n",
    "# Crear los tensores de entrenamiento/validación usando los índices\n",
    "try:\n",
    "    train_input = input_tensor_normalized[train_idx]\n",
    "    train_target = target_tensor_normalized[train_idx]\n",
    "    val_input = input_tensor_normalized[val_idx]\n",
    "    val_target = target_tensor_normalized[val_idx]\n",
    "    print(f\"Forma datos entrenamiento (Input): {train_input.shape}\")\n",
    "    print(f\"Forma datos validación (Input): {val_input.shape}\")\n",
    "except IndexError:\n",
    "     print(\"Error al crear subconjuntos de datos. ¿Coinciden los índices con las dimensiones?\")\n",
    "     exit()\n",
    "\n",
    "# --- 4. Definición del Modelo Transformer (con ReLU al final) ---\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model) # Shape: (1, max_len, d_model) para batch_first\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Args: x: Tensor, shape [batch_size, seq_len, d_model] \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout, batch_first=True, activation=F.gelu\n",
    "        )\n",
    "        encoder_norm = nn.LayerNorm(d_model)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers, norm=encoder_norm)\n",
    "\n",
    "        self.output_proj = nn.Linear(d_model, output_dim)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.input_proj.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.input_proj.bias)\n",
    "        nn.init.uniform_(self.output_proj.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.output_proj.bias)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        src = self.input_proj(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        output = self.output_proj(output)\n",
    "        output = F.relu(output) # Asegurar salida no negativa\n",
    "        return output\n",
    "\n",
    "# --- 5. Funciones de Entrenamiento, Evaluación y Predicción ---\n",
    "\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_input, batch_target in data_loader:\n",
    "        batch_input, batch_target = batch_input.to(device), batch_target.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        use_amp_here = scaler is not None\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp_here):\n",
    "            output = model(batch_input)\n",
    "            loss = criterion(output, batch_target)\n",
    "\n",
    "        if use_amp_here:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer) # Desescalar antes de clip\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate_epoch(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_input, batch_target in data_loader:\n",
    "            batch_input, batch_target = batch_input.to(device), batch_target.to(device)\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')): # AMP también en eval\n",
    "                 output = model(batch_input)\n",
    "                 loss = criterion(output, batch_target)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, model_save_path='best_transformer_model.pth', use_amp=False):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    patience = 15\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp and device.type == 'cuda' else None\n",
    "    if scaler: print(\"Usando Precisión Mixta Automática (AMP) para el entrenamiento.\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, scaler)\n",
    "        val_loss = evaluate_epoch(model, val_loader, criterion, device)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Validar pérdida de validación\n",
    "        if np.isnan(val_loss) or np.isinf(val_loss):\n",
    "            print(f\"Epoch {epoch+1:03d}/{num_epochs}: Pérdida de validación inválida ({val_loss}). Deteniendo entrenamiento.\")\n",
    "            break # Detener si la pérdida diverge\n",
    "\n",
    "        lr_current = optimizer.param_groups[0]['lr']\n",
    "        print(f'Epoch {epoch+1:03d}/{num_epochs}, Train Loss: {train_loss:.5f}, Val Loss: {val_loss:.5f}, LR: {lr_current:.6f}, Time: {end_time - start_time:.2f}s')\n",
    "\n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                 scheduler.step(val_loss)\n",
    "            # Añadir 'else' si usas otros tipos de scheduler que requieran step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            try:\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                print(f'    --> Modelo guardado en {model_save_path} (Val Loss: {best_val_loss:.5f})')\n",
    "            except Exception as e:\n",
    "                print(f\"    --> ERROR al guardar el modelo: {e}\")\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'    --> Early stopping activado tras {patience} épocas sin mejora.')\n",
    "            break\n",
    "\n",
    "    print(f'Entrenamiento finalizado. Mejor Val Loss: {best_val_loss:.5f}')\n",
    "    # Cargar el mejor modelo al final para devolverlo\n",
    "    if best_val_loss != float('inf'): # Solo cargar si se guardó algo\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(model_save_path))\n",
    "            print(f\"Mejor modelo cargado desde {model_save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar el mejor modelo guardado: {e}\")\n",
    "    else:\n",
    "        print(\"Advertencia: No se guardó ningún modelo (la pérdida de validación nunca mejoró).\")\n",
    "\n",
    "    return best_val_loss, model\n",
    "\n",
    "# --- Función para Predicción de un Solo Escenario ---\n",
    "def predict_single_scenario(model, scenario_input_original, scaler_input, scaler_target, device):\n",
    "    model.eval()\n",
    "    if isinstance(scenario_input_original, torch.Tensor):\n",
    "        input_np_original = scenario_input_original.cpu().numpy()\n",
    "    else:\n",
    "        input_np_original = np.array(scenario_input_original)\n",
    "\n",
    "    if input_np_original.ndim != 2:\n",
    "         raise ValueError(f\"La entrada del escenario debe ser 2D (seq_len, features), pero tiene forma {input_np_original.shape}\")\n",
    "\n",
    "    seq_len, expected_features = input_np_original.shape\n",
    "    if not hasattr(scaler_input, 'n_features_in_') or expected_features != scaler_input.n_features_in_:\n",
    "         # Añadir chequeo por si el scaler no está ajustado o las features no coinciden\n",
    "         raise ValueError(f\"Inconsistencia en características de entrada: Scaler espera {getattr(scaler_input, 'n_features_in_', 'N/A')} features, datos tienen {expected_features}.\")\n",
    "\n",
    "    input_np_normalized = scaler_input.transform(input_np_original)\n",
    "    input_tensor_norm = torch.tensor(input_np_normalized, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n",
    "             predicted_output_normalized = model(input_tensor_norm)\n",
    "\n",
    "    pred_np_norm = predicted_output_normalized.squeeze(0).cpu().numpy()\n",
    "    pred_np_denorm = scaler_target.inverse_transform(pred_np_norm)\n",
    "    pred_np_denorm = np.maximum(pred_np_denorm, 0) # Clip final\n",
    "    return pred_np_denorm\n",
    "\n",
    "\n",
    "# --- 6. Optimización de Hiperparámetros con Optuna ---\n",
    "\n",
    "# Obtener dimensiones y dispositivo\n",
    "try:\n",
    "    INPUT_DIM = train_input.shape[-1]\n",
    "    OUTPUT_DIM = train_target.shape[-1]\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "    print(f\"Usando dispositivo: {DEVICE}\")\n",
    "    print(f\"Input dim: {INPUT_DIM}, Output dim: {OUTPUT_DIM}\")\n",
    "    USE_AMP = (DEVICE.type == 'cuda') # Usar AMP solo si es CUDA\n",
    "except Exception as e:\n",
    "    print(f\"Error al determinar dimensiones o dispositivo: {e}. Saliendo.\")\n",
    "    exit()\n",
    "\n",
    "def objective(trial):\n",
    "    d_model = trial.suggest_categorical('d_model', [64, 128, 256])\n",
    "    ff_multiplier = trial.suggest_categorical('ff_multiplier', [2, 4])\n",
    "    dim_feedforward = d_model * ff_multiplier\n",
    "    trial.set_user_attr('calculated_dim_feedforward', dim_feedforward)\n",
    "\n",
    "    possible_nheads = [h for h in [2, 4, 8, 16] if d_model % h == 0] # Añadido 16\n",
    "    if not possible_nheads: nhead = 2\n",
    "    else: nhead = trial.suggest_categorical('nhead', possible_nheads)\n",
    "\n",
    "    num_encoder_layers = trial.suggest_int('num_encoder_layers', 1, 6) # Aumentado rango\n",
    "    dropout = trial.suggest_float('dropout', 0.05, 0.35) # Rango ajustado\n",
    "    learning_rate = trial.suggest_float('learning_rate', 5e-6, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128]) # Añadido 128\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-7, 1e-3, log=True)\n",
    "\n",
    "    # DataLoaders para el trial\n",
    "    try:\n",
    "        train_loader = DataLoader(TensorDataset(train_input, train_target), batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, persistent_workers=True)\n",
    "        val_loader = DataLoader(TensorDataset(val_input, val_target), batch_size=batch_size, num_workers=2, pin_memory=True, persistent_workers=True)\n",
    "    except Exception: # Fallback más general\n",
    "        print(\"Warning: DataLoader con workers/pin_memory falló, usando configuración básica.\")\n",
    "        train_loader = DataLoader(TensorDataset(train_input, train_target), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(val_input, val_target), batch_size=batch_size)\n",
    "\n",
    "    model = TransformerModel(\n",
    "        input_dim=INPUT_DIM, output_dim=OUTPUT_DIM, d_model=d_model, nhead=nhead,\n",
    "        num_encoder_layers=num_encoder_layers, dim_feedforward=dim_feedforward, dropout=dropout\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=False)\n",
    "    scaler_optuna = torch.cuda.amp.GradScaler() if USE_AMP else None\n",
    "\n",
    "    num_optuna_epochs = 30\n",
    "    print(f\"\\n--- Optuna Trial {trial.number} ---\")\n",
    "    print(f\"Params: d_model={d_model}, nhead={nhead}, layers={num_encoder_layers}, ff={dim_feedforward}({ff_multiplier}x), drop={dropout:.3f}, lr={learning_rate:.6f}, bs={batch_size}, wd={weight_decay:.7f}\")\n",
    "\n",
    "    best_trial_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    patience_optuna = 7\n",
    "\n",
    "    for epoch in range(num_optuna_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, DEVICE, scaler_optuna)\n",
    "        val_loss = evaluate_epoch(model, val_loader, criterion, DEVICE)\n",
    "\n",
    "        if np.isnan(val_loss) or np.isinf(val_loss):\n",
    "             print(f\"    --> Trial {trial.number} divergió (Val Loss: {val_loss}). Podando.\")\n",
    "             raise optuna.TrialPruned()\n",
    "\n",
    "        print(f'    Epoch {epoch+1:02d}/{num_optuna_epochs}, Train Loss: {train_loss:.5f}, Val Loss: {val_loss:.5f}')\n",
    "        if scheduler: scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_trial_val_loss:\n",
    "            best_trial_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "             epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience_optuna:\n",
    "             print(f'    --> Optuna trial early stopping at epoch {epoch+1}. Val Loss: {best_trial_val_loss:.5f}')\n",
    "             break\n",
    "\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            print(f\"    --> Trial {trial.number} podado en la época {epoch+1}.\")\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return best_trial_val_loss\n",
    "\n",
    "# Ejecutar Optuna\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- INICIANDO OPTIMIZACIÓN CON OPTUNA ---\")\n",
    "study_name = \"transformer_optimization_v1\" # Nombre para posible reanudación\n",
    "storage_name = f\"sqlite:///{study_name}.db\" # Guardar estudio en archivo sqlite\n",
    "\n",
    "try:\n",
    "    # Intentar cargar estudio existente o crear uno nuevo\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage_name,\n",
    "        direction='minimize',\n",
    "        sampler=optuna.samplers.TPESampler(seed=random_seed),\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), # Podar tras 5 épocas\n",
    "        load_if_exists=True # Cargar si ya existe\n",
    "    )\n",
    "    print(f\"Estudio Optuna '{study_name}' cargado/creado desde '{storage_name}'.\")\n",
    "    print(f\"Número de trials ya completados: {len(study.trials)}\")\n",
    "\n",
    "    # Ejecutar optimize\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=25, # Número de NUEVOS trials a ejecutar\n",
    "        timeout=None, # Sin límite de tiempo\n",
    "        n_jobs=1, # Usar 1 job para evitar problemas con GPU/MPS\n",
    "        catch=(ValueError, RuntimeError, ) # Capturar errores comunes sin detener todo el estudio\n",
    "    )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nOptimización interrumpida por el usuario.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError durante la optimización de Optuna: {e}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Obtener mejores parámetros\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- OPTIMIZACIÓN FINALIZADA ---\")\n",
    "best_params = {}\n",
    "best_value = float('inf')\n",
    "\n",
    "try:\n",
    "    if study.best_trial:\n",
    "        best_params = study.best_trial.params\n",
    "        best_value = study.best_trial.value\n",
    "        print(f\"Mejor Valor (Val Loss): {best_value:.5f}\")\n",
    "        print(\"Mejores Hiperparámetros encontrados:\")\n",
    "        print(best_params)\n",
    "        # Añadir valor calculado\n",
    "        if 'ff_multiplier' in best_params and 'd_model' in best_params:\n",
    "            best_params['calculated_dim_feedforward'] = best_params['d_model'] * best_params['ff_multiplier']\n",
    "    else:\n",
    "        print(\"No se encontró un 'best_trial' en el estudio Optuna.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al obtener resultados de Optuna: {e}\")\n",
    "\n",
    "# Fallback a parámetros por defecto si Optuna falló o no encontró nada\n",
    "if not best_params:\n",
    "    print(\"Usando parámetros por defecto debido a fallo o falta de resultados en Optuna.\")\n",
    "    best_params = {'d_model': 128, 'ff_multiplier': 4, 'nhead': 4, 'num_encoder_layers': 3,\n",
    "                   'dropout': 0.15, 'learning_rate': 0.0005, 'batch_size': 64, 'weight_decay': 1e-5}\n",
    "    # Calcular dim_feedforward para los por defecto\n",
    "    best_params['calculated_dim_feedforward'] = best_params['d_model'] * best_params['ff_multiplier']\n",
    "    print(f\"Parámetros por defecto: {best_params}\")\n",
    "\n",
    "\n",
    "# Ajuste final de nhead (redundante si la lógica en objective es correcta)\n",
    "if 'd_model' in best_params:\n",
    "    d_model = best_params['d_model']\n",
    "    possible_nheads = [h for h in [2, 4, 8, 16] if d_model % h == 0]\n",
    "    if not possible_nheads:\n",
    "        best_params['nhead'] = 2 # Fallback\n",
    "    elif 'nhead' not in best_params or best_params['nhead'] not in possible_nheads:\n",
    "        best_params['nhead'] = possible_nheads[0] # Elegir el primero compatible\n",
    "        print(f\"Ajuste post-optuna: nhead establecido a {best_params['nhead']} para ser compatible con d_model={d_model}\")\n",
    "else:\n",
    "     # Si ni siquiera d_model está, algo falló gravemente\n",
    "     print(\"Error crítico: 'd_model' no encontrado en best_params. Usando nhead=4 por defecto.\")\n",
    "     best_params['nhead'] = 4\n",
    "\n",
    "\n",
    "# --- 7. Entrenamiento Final con los Mejores Hiperparámetros ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- INICIANDO ENTRENAMIENTO FINAL ---\")\n",
    "print(f\"Usando parámetros: {best_params}\")\n",
    "\n",
    "# Crear DataLoaders finales\n",
    "final_batch_size = best_params.get('batch_size', 64) # Usar get con default\n",
    "try:\n",
    "    final_train_loader = DataLoader(TensorDataset(train_input, train_target), batch_size=final_batch_size, shuffle=True, num_workers=2, pin_memory=True, persistent_workers=True)\n",
    "    final_val_loader = DataLoader(TensorDataset(val_input, val_target), batch_size=final_batch_size, num_workers=2, pin_memory=True, persistent_workers=True)\n",
    "except Exception:\n",
    "    print(\"Warning: DataLoader con workers/pin_memory falló, usando configuración básica.\")\n",
    "    final_train_loader = DataLoader(TensorDataset(train_input, train_target), batch_size=final_batch_size, shuffle=True)\n",
    "    final_val_loader = DataLoader(TensorDataset(val_input, val_target), batch_size=final_batch_size)\n",
    "\n",
    "# Crear el modelo final\n",
    "try:\n",
    "    final_model = TransformerModel(\n",
    "        input_dim=INPUT_DIM,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        d_model=best_params['d_model'],\n",
    "        nhead=best_params['nhead'],\n",
    "        num_encoder_layers=best_params['num_encoder_layers'],\n",
    "        dim_feedforward=best_params['calculated_dim_feedforward'], # Usa el valor calculado\n",
    "        dropout=best_params['dropout']\n",
    "    ).to(DEVICE)\n",
    "except KeyError as e:\n",
    "     print(f\"Error: Falta el hiperparámetro '{e}' en best_params. No se puede crear el modelo final.\")\n",
    "     exit()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(final_model.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
    "final_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.5, verbose=True)\n",
    "\n",
    "# Entrenar\n",
    "final_num_epochs = 150 # Ajusta según necesidad\n",
    "model_save_filename = 'best_transformer_model_relu.pth'\n",
    "best_final_loss, final_model = train_model(\n",
    "    final_model, final_train_loader, final_val_loader, criterion, optimizer, final_scheduler,\n",
    "    num_epochs=final_num_epochs, device=DEVICE, model_save_path=model_save_filename, use_amp=USE_AMP\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- SCRIPT DE ENTRENAMIENTO FINALIZADO ---\")\n",
    "print(f\"Modelo final (con ReLU) entrenado. Mejor Loss de Validación: {best_final_loss:.5f}\")\n",
    "print(f\"Modelo guardado como '{model_save_filename}'.\")\n",
    "print(\"Los scalers (scaler_input, scaler_target) son necesarios para usar el modelo en datos nuevos.\")\n",
    "print(\"Los índices de entrenamiento/validación están en 'train_idx' y 'val_idx'.\")\n",
    "\n",
    "\n",
    "# --- 8. Prueba con un Escenario Específico (Usando la función definida) ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- PRUEBA CON UN ESCENARIO ESPECÍFICO ---\")\n",
    "\n",
    "# Asegurarse de que las variables necesarias existen\n",
    "required_vars_test = ['final_model', 'scaler_input', 'scaler_target', 'input_tensor', 'target_tensor', 'DEVICE']\n",
    "if all(var in globals() for var in required_vars_test):\n",
    "\n",
    "    # === PASO 1: Elige el índice del escenario a probar ===\n",
    "    if 'val_idx' in globals() and len(val_idx) > 0:\n",
    "        test_scenario_index = val_idx[0] # Primer escenario de validación\n",
    "        print(f\"Se probará con el escenario de índice original: {test_scenario_index} (pertenece al conjunto de validación)\")\n",
    "    else:\n",
    "        test_scenario_index = 0 # Primer escenario del dataset\n",
    "        if test_scenario_index < input_tensor.shape[0]:\n",
    "             print(f\"Se probará con el escenario de índice original: {test_scenario_index} (No hay datos de validación, usando índice 0)\")\n",
    "        else:\n",
    "             print(f\"Error: No hay datos disponibles para probar (índice {test_scenario_index} inválido).\")\n",
    "             test_scenario_index = -1 # Marcar como inválido\n",
    "\n",
    "    if test_scenario_index != -1:\n",
    "        # === PASO 2: Obtén los datos ORIGINALES (antes de normalizar) ===\n",
    "        try:\n",
    "            single_input_original = input_tensor[test_scenario_index]\n",
    "            single_target_original = target_tensor[test_scenario_index]\n",
    "            print(f\"Forma de la entrada original del escenario: {single_input_original.shape}\")\n",
    "        except IndexError:\n",
    "            print(f\"Error fatal: No se pudo acceder al índice {test_scenario_index} en los tensores originales.\")\n",
    "            test_scenario_index = -1 # Marcar como inválido\n",
    "\n",
    "    if test_scenario_index != -1:\n",
    "        # === PASO 3: Realiza la predicción ===\n",
    "        try:\n",
    "            start_pred_time = time.time()\n",
    "            prediction_denormalized = predict_single_scenario(\n",
    "                final_model, single_input_original, scaler_input, scaler_target, DEVICE\n",
    "            )\n",
    "            end_pred_time = time.time()\n",
    "            print(f\"Predicción realizada en {end_pred_time - start_pred_time:.4f} segundos.\")\n",
    "            print(f\"\\nPredicción para el escenario {test_scenario_index} (Desnormalizada):\")\n",
    "            print(\"Forma:\", prediction_denormalized.shape)\n",
    "            print(\"Primeros 5 pasos:\\n\", prediction_denormalized[:5, :])\n",
    "\n",
    "            # === PASO 4: (Opcional) Compara con el valor real ===\n",
    "            if isinstance(single_target_original, torch.Tensor):\n",
    "                target_np_original = single_target_original.cpu().numpy()\n",
    "            else:\n",
    "                 target_np_original = np.array(single_target_original)\n",
    "\n",
    "            print(f\"\\nValor Real para el escenario {test_scenario_index} (Original):\")\n",
    "            print(\"Forma:\", target_np_original.shape)\n",
    "            print(\"Primeros 5 pasos:\\n\", target_np_original[:5, :])\n",
    "\n",
    "            # Calcular error\n",
    "            mae_escenario = np.mean(np.abs(prediction_denormalized - target_np_original))\n",
    "            rmse_escenario = np.sqrt(np.mean((prediction_denormalized - target_np_original)**2))\n",
    "            print(f\"\\nError Absoluto Medio (MAE) para este escenario: {mae_escenario:.5f}\")\n",
    "            print(f\"Raíz del Error Cuadrático Medio (RMSE) para este escenario: {rmse_escenario:.5f}\")\n",
    "\n",
    "            # Verificar no negatividad final\n",
    "            if np.any(prediction_denormalized < 0):\n",
    "                 print(\"\\n¡ADVERTENCIA! Se encontraron valores < 0 en la predicción desnormalizada final.\")\n",
    "            else:\n",
    "                 print(\"\\nConfirmado: No hay valores < 0 en la predicción desnormalizada final.\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n*** Error durante la predicción del escenario específico: ***\")\n",
    "            print(e)\n",
    "            traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo se puede ejecutar la prueba de escenario específico.\")\n",
    "    print(\"Asegúrate de que el entrenamiento se completó y las variables\")\n",
    "    print(f\"{required_vars_test} están disponibles en el entorno.\")\n",
    "\n",
    "print(\"=\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas del modelo en los datos de validación:\n",
      "Pérdida promedio (MSE normalizado): 1.8232\n",
      "Error Cuadrático Medio (MSE desnormalizado): 16.5326\n",
      "Error Absoluto Medio (MAE desnormalizado): 3.1601\n",
      "Coeficiente de Determinación (R² desnormalizado): -0.8002\n",
      "\n",
      "Prueba con un ejemplo específico (primer escenario de validación):\n",
      "Predicciones (desnormalizadas) para los primeros 5 pares de relés:\n",
      "Par 1:\n",
      "  Predicción: [ 0.43002382  7.486592   12.017996    4.080612  ]\n",
      "  Valor real: [10.739031   1.9509555  5.9624233  1.2299176]\n",
      "Par 2:\n",
      "  Predicción: [0.11465684 5.9169545  9.741835   2.696026  ]\n",
      "  Valor real: [1.0115863 4.9236174 3.1815815 7.994131 ]\n",
      "Par 3:\n",
      "  Predicción: [ 1.259947    5.960698    2.5113537  -0.33478466]\n",
      "  Valor real: [9.688989  9.712443  3.1813238 5.280407 ]\n",
      "Par 4:\n",
      "  Predicción: [0.7969634 1.1996793 9.026089  2.500911 ]\n",
      "  Valor real: [ 6.613281   3.8063807  1.4643133 17.902504 ]\n",
      "Par 5:\n",
      "  Predicción: [2.8568864 2.7802656 6.520256  5.565122 ]\n",
      "  Valor real: [2.7434456 2.0836818 3.997959  6.692013 ]\n",
      "Par 6:\n",
      "  Predicción: [ 3.4507482  3.2240183  3.1629286 -4.626836 ]\n",
      "  Valor real: [5.446667   0.76408017 0.32223743 8.774572  ]\n",
      "Par 7:\n",
      "  Predicción: [ 0.67186016 -0.3688101   6.4581666   4.0898247 ]\n",
      "  Valor real: [10.337916   4.052724   2.964671   6.2483716]\n",
      "Par 8:\n",
      "  Predicción: [ 3.7976735  1.481093   4.114342  -3.0410135]\n",
      "  Valor real: [1.7131342 1.9990569 3.4551752 9.224229 ]\n",
      "Par 9:\n",
      "  Predicción: [-0.293542   3.7109869  5.2644563  3.4523735]\n",
      "  Valor real: [5.5714684 3.5652971 8.631158  1.591575 ]\n",
      "Par 10:\n",
      "  Predicción: [ 2.4828484  -1.9382676   4.6962857  -0.30147567]\n",
      "  Valor real: [ 0.4521195 16.102919   3.716651   4.183337 ]\n",
      "Par 11:\n",
      "  Predicción: [0.01014606 3.724056   6.821495   4.674536  ]\n",
      "  Valor real: [3.5202253 2.236049  4.6208515 1.0008548]\n",
      "Par 12:\n",
      "  Predicción: [0.67463225 9.032503   8.096059   3.762111  ]\n",
      "  Valor real: [ 6.3913226  1.2410597 11.790919   1.0564686]\n",
      "Par 13:\n",
      "  Predicción: [ 0.7086083  -0.09935512  2.3465106   3.0246735 ]\n",
      "  Valor real: [3.3245568 5.9145727 3.4339237 1.8960413]\n",
      "Par 14:\n",
      "  Predicción: [-0.19750032 11.524216   10.1800995   3.9322267 ]\n",
      "  Valor real: [ 0.03191534  0.72926056 10.26842     1.479237  ]\n",
      "Par 15:\n",
      "  Predicción: [0.90178436 0.9844154  4.8589034  1.2951704 ]\n",
      "  Valor real: [ 0.9682302 10.966547   4.405202   3.9707074]\n",
      "Par 16:\n",
      "  Predicción: [ 7.3671     1.0266405  2.674165  -4.427678 ]\n",
      "  Valor real: [1.2856184 1.5171508 4.660883  4.6672745]\n",
      "Par 17:\n",
      "  Predicción: [ 2.5990255  -0.79279697  1.842639    1.3000413 ]\n",
      "  Valor real: [3.6430647 2.1286113 1.466702  2.2755985]\n",
      "Par 18:\n",
      "  Predicción: [-0.2696825 11.139704   3.5286317  7.2570796]\n",
      "  Valor real: [4.220655  9.867164  7.7515244 1.0049506]\n",
      "Par 19:\n",
      "  Predicción: [ 1.3424047  10.079391    2.438206    0.97632134]\n",
      "  Valor real: [0.32554832 8.847144   9.117647   1.0697225 ]\n",
      "Par 20:\n",
      "  Predicción: [0.39840332 7.9629483  7.242237   2.77194   ]\n",
      "  Valor real: [4.047528  5.846592  1.4151492 5.7100196]\n",
      "Par 21:\n",
      "  Predicción: [0.7263698 9.352947  8.730229  2.723126 ]\n",
      "  Valor real: [1.3511552 5.2900496 7.496119  1.3599564]\n",
      "Par 22:\n",
      "  Predicción: [3.0797534  0.07286678 3.6695518  3.941944  ]\n",
      "  Valor real: [ 6.752387   3.4072595  9.326214  11.664846 ]\n",
      "Par 23:\n",
      "  Predicción: [ 1.874951  10.143524   1.1237192  2.0164974]\n",
      "  Valor real: [ 2.983932   13.132991    0.74027103  1.7598528 ]\n",
      "Par 24:\n",
      "  Predicción: [0.22108665 5.4890113  4.083417   2.7350168 ]\n",
      "  Valor real: [2.9449148 6.0660095 5.79373   4.3468714]\n",
      "Par 25:\n",
      "  Predicción: [3.0158541 1.4665452 6.491772  3.8804612]\n",
      "  Valor real: [1.1687587  5.310412   1.2818959  0.15030728]\n",
      "Par 26:\n",
      "  Predicción: [ 2.361139  -0.4475645  2.0444205 -1.6731006]\n",
      "  Valor real: [3.782939  1.1476866 3.0462668 3.5873735]\n",
      "Par 27:\n",
      "  Predicción: [-0.33799705 11.654805    3.797393    5.6460376 ]\n",
      "  Valor real: [5.68437    9.329428   0.25463146 3.847419  ]\n",
      "Par 28:\n",
      "  Predicción: [ 1.6783689 -1.5930251  5.766142   4.59943  ]\n",
      "  Valor real: [0.31875768 1.5746948  8.135254   4.9267907 ]\n",
      "Par 29:\n",
      "  Predicción: [1.9622458 4.188453  2.7099912 1.2399684]\n",
      "  Valor real: [6.305704  1.3632733 1.4655709 4.2539525]\n",
      "Par 30:\n",
      "  Predicción: [-0.11828955  8.680228    6.78592     4.9069676 ]\n",
      "  Valor real: [0.056132   7.093011   0.13576263 0.1977738 ]\n",
      "Par 31:\n",
      "  Predicción: [ 4.055406   1.9551741  2.8090909 -5.122511 ]\n",
      "  Valor real: [3.8745756 4.4773965 1.5076008 7.0817804]\n",
      "Par 32:\n",
      "  Predicción: [ 3.234844   3.4549198  1.921411  -2.6899517]\n",
      "  Valor real: [1.0095576 1.4559356 2.3035772 8.795785 ]\n",
      "Par 33:\n",
      "  Predicción: [ 1.9013659  5.7887     0.5061938 -1.0555645]\n",
      "  Valor real: [2.073323   1.4177886  8.384387   0.81593525]\n",
      "Par 34:\n",
      "  Predicción: [-0.31847915 10.412508    4.7633524   5.99032   ]\n",
      "  Valor real: [5.033446   1.4305345  0.32642406 5.0747657 ]\n",
      "Par 35:\n",
      "  Predicción: [ 3.3935697  6.6798306  1.3397005 -3.3775713]\n",
      "  Valor real: [ 6.856158   8.231676   5.9647174 12.0353985]\n",
      "Par 36:\n",
      "  Predicción: [3.2139566 2.3199348 2.7307017 3.6122046]\n",
      "  Valor real: [2.1933165  0.18971835 5.849737   0.78165543]\n",
      "Par 37:\n",
      "  Predicción: [ 3.3726583  1.9444681  2.8042123 -1.8273493]\n",
      "  Valor real: [1.642104  8.719038  4.1380496 3.1387181]\n",
      "Par 38:\n",
      "  Predicción: [ 0.7847914  3.0041344 10.099133   1.5911702]\n",
      "  Valor real: [1.4706959 2.5744627 6.052864  3.7715886]\n",
      "Par 39:\n",
      "  Predicción: [ 3.4862132  9.020121   1.4123044 -4.57913  ]\n",
      "  Valor real: [2.967141  5.4067974 2.208415  1.183698 ]\n",
      "Par 40:\n",
      "  Predicción: [ 0.6787948 10.826635   4.9583344  5.992133 ]\n",
      "  Valor real: [5.0834394 0.6503161 5.4685807 3.4882352]\n",
      "Par 41:\n",
      "  Predicción: [0.8542182 9.590123  9.473935  5.0976634]\n",
      "  Valor real: [0.8793182 0.5447632 8.0654335 3.3661842]\n",
      "Par 42:\n",
      "  Predicción: [0.9371273 0.751438  2.0942354 1.7606863]\n",
      "  Valor real: [4.8821607 4.5639353 3.8355567 1.6202205]\n",
      "Par 43:\n",
      "  Predicción: [1.2882584 0.5680791 4.7096286 2.397326 ]\n",
      "  Valor real: [1.8644489  5.4262614  1.5524163  0.40838465]\n",
      "Par 44:\n",
      "  Predicción: [ 2.0604584  1.1468035  2.3687105 -2.0248778]\n",
      "  Valor real: [ 1.7011415 13.07938    3.7014656  2.0849104]\n",
      "Par 45:\n",
      "  Predicción: [ 2.3802369   0.20750175  1.843302   -0.8576547 ]\n",
      "  Valor real: [3.1105568 3.7671623 5.7829742 2.379733 ]\n",
      "Par 46:\n",
      "  Predicción: [6.245243   0.03092704 2.4678187  3.8100235 ]\n",
      "  Valor real: [0.7957186  4.770934   5.389949   0.80153406]\n",
      "Par 47:\n",
      "  Predicción: [ 4.926563   -0.54336154  3.0298402  -2.0798833 ]\n",
      "  Valor real: [0.50802726 0.5951625  9.570521   3.3727038 ]\n",
      "Par 48:\n",
      "  Predicción: [1.1103939 9.210509  8.278793  3.0644672]\n",
      "  Valor real: [5.337193  1.316094  4.6734304 7.1342   ]\n",
      "Par 49:\n",
      "  Predicción: [3.4131114 0.8612789 3.4571457 4.52071  ]\n",
      "  Valor real: [1.1457249  3.6456025  3.1470811  0.18233524]\n",
      "Par 50:\n",
      "  Predicción: [2.9059765 2.8210664 4.293899  4.9240775]\n",
      "  Valor real: [1.9629585 1.0632869 4.468764  1.1486639]\n",
      "Par 51:\n",
      "  Predicción: [ 2.2204278 -1.3833755  3.2253792 11.071553 ]\n",
      "  Valor real: [0.27441445 0.19883619 1.9453671  2.8893404 ]\n",
      "Par 52:\n",
      "  Predicción: [0.9197666  5.831341   5.3475256  0.40885767]\n",
      "  Valor real: [3.3029728 1.5505301 2.4937038 8.123409 ]\n",
      "Par 53:\n",
      "  Predicción: [4.43305    0.06383381 4.379544   5.0562296 ]\n",
      "  Valor real: [5.902038  4.2976894 5.8596563 9.695805 ]\n",
      "Par 54:\n",
      "  Predicción: [ 1.903618   4.1221366  4.362469  -0.4878389]\n",
      "  Valor real: [2.2796123 8.082634  0.6806068 1.3754708]\n",
      "Par 55:\n",
      "  Predicción: [ 2.6116917  4.645106   2.7429194 -0.9331733]\n",
      "  Valor real: [0.5378732  6.5021033  5.3554587  0.42965946]\n",
      "Par 56:\n",
      "  Predicción: [0.29342642 8.231808   8.528126   2.1849856 ]\n",
      "  Valor real: [2.9973621 4.2892156 4.1704764 2.1113167]\n",
      "Par 57:\n",
      "  Predicción: [0.52124375 2.8775456  6.733421   6.746182  ]\n",
      "  Valor real: [1.2202314 7.5996165 2.8003538 7.0309896]\n",
      "Par 58:\n",
      "  Predicción: [ 5.2444425 -0.1155714  3.9924493 -3.9333222]\n",
      "  Valor real: [3.468267  6.7502184 2.0243094 5.629449 ]\n",
      "Par 59:\n",
      "  Predicción: [1.3870178  0.17709528 2.5225499  0.5446092 ]\n",
      "  Valor real: [0.85535663 6.534248   6.613345   5.549414  ]\n",
      "Par 60:\n",
      "  Predicción: [ 5.59492   -1.9939016  2.5440776  3.358046 ]\n",
      "  Valor real: [0.61996645 1.1529192  5.990198   1.4874567 ]\n",
      "Par 61:\n",
      "  Predicción: [ 1.3036875 -2.3079033  2.4185243  4.1914926]\n",
      "  Valor real: [5.027395   0.82101405 2.7917612  1.8798615 ]\n",
      "Par 62:\n",
      "  Predicción: [ 3.278086   -0.28651753  2.7118855  -3.9557183 ]\n",
      "  Valor real: [ 9.287455  12.582001   6.477523   1.9839591]\n",
      "Par 63:\n",
      "  Predicción: [ 8.37924     0.73465073  2.3843539  -4.51731   ]\n",
      "  Valor real: [2.6601644 1.7506744 7.6714516 7.7684236]\n",
      "Par 64:\n",
      "  Predicción: [ 2.9820929  1.6853675  1.2438693 -3.2952263]\n",
      "  Valor real: [6.476263 4.444087 5.3638   5.753688]\n",
      "Par 65:\n",
      "  Predicción: [ 5.7820425   0.30122098  3.343768   -1.7055379 ]\n",
      "  Valor real: [1.7211818 2.0403478 2.0777729 5.3574133]\n",
      "Par 66:\n",
      "  Predicción: [0.69358224 5.695267   5.343137   0.75376594]\n",
      "  Valor real: [1.9303702  0.59318817 0.8273062  4.5274773 ]\n",
      "Par 67:\n",
      "  Predicción: [0.90789956 4.4284334  8.657528   4.2284064 ]\n",
      "  Valor real: [2.0642445  0.70102966 0.7254955  2.7407684 ]\n",
      "Par 68:\n",
      "  Predicción: [1.2473484  0.76813114 2.2175753  1.0123519 ]\n",
      "  Valor real: [5.334349   1.5817448  2.7392454  0.79580486]\n",
      "Par 69:\n",
      "  Predicción: [ 4.941469   7.557953   1.2166834 -4.7748394]\n",
      "  Valor real: [3.230144  3.3496668 0.6843888 6.221683 ]\n",
      "Par 70:\n",
      "  Predicción: [ 5.136879   2.0941498  2.4676108 -4.6949654]\n",
      "  Valor real: [2.9066792  3.7233338  0.96328586 2.251356  ]\n",
      "Par 71:\n",
      "  Predicción: [ 2.2910686  -0.15885772  7.660257    6.7770166 ]\n",
      "  Valor real: [8.876204  7.6072097 0.473715  8.863152 ]\n",
      "Par 72:\n",
      "  Predicción: [2.3268454 7.1653724 0.9969918 2.4914818]\n",
      "  Valor real: [4.2859893 2.0128336 3.0205436 0.9434403]\n",
      "Par 73:\n",
      "  Predicción: [-0.09013041 -0.47303095  2.1338704   8.686458  ]\n",
      "  Valor real: [0.53679675 7.498674   1.321104   5.4331665 ]\n",
      "Par 74:\n",
      "  Predicción: [ 2.1591396   7.33177     3.2402778  -0.70131505]\n",
      "  Valor real: [3.4001458 6.2162614 4.300987  3.8985047]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "\n",
    "# Definir la clase PositionalEncoding (necesaria para el Transformer)\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "# Definir la clase del modelo Transformer (necesaria para cargar el modelo)\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Proyección lineal para ajustar la dimensión de entrada a d_model\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "\n",
    "        # Capas del Transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "\n",
    "        # Proyección lineal para la salida\n",
    "        self.output_proj = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src shape: (batch_size, seq_len, input_dim)\n",
    "        src = self.input_proj(src)  # Proyectar a d_model\n",
    "        src = src.permute(1, 0, 2)  # Cambiar a (seq_len, batch_size, d_model) para Transformer\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.permute(1, 0, 2)  # Volver a (batch_size, seq_len, d_model)\n",
    "        output = self.output_proj(output)  # Proyectar a output_dim\n",
    "        return output\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "def load_model(model_path, input_dim, output_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout, device):\n",
    "    model = TransformerModel(\n",
    "        input_dim=input_dim,\n",
    "        output_dim=output_dim,\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        num_encoder_layers=num_encoder_layers,\n",
    "        dim_feedforward=dim_feedforward,\n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Función para evaluar el modelo y calcular métricas\n",
    "def evaluate_model(model, data_loader, criterion, scaler_target, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_input, batch_target in data_loader:\n",
    "            batch_input, batch_target = batch_input.to(device), batch_target.to(device)\n",
    "            output = model(batch_input)\n",
    "            loss = criterion(output, batch_target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Guardar predicciones y valores reales\n",
    "            all_preds.append(output.cpu().numpy())\n",
    "            all_targets.append(batch_target.cpu().numpy())\n",
    "\n",
    "    # Concatenar todas las predicciones y valores reales\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    # Desnormalizar las predicciones y los valores reales\n",
    "    all_preds_denorm = scaler_target.inverse_transform(all_preds.reshape(-1, all_preds.shape[-1])).reshape(all_preds.shape)\n",
    "    all_targets_denorm = scaler_target.inverse_transform(all_targets.reshape(-1, all_targets.shape[-1])).reshape(all_targets.shape)\n",
    "\n",
    "    # Calcular métricas en la escala original\n",
    "    mse = mean_squared_error(all_targets_denorm.reshape(-1), all_preds_denorm.reshape(-1))\n",
    "    mae = mean_absolute_error(all_targets_denorm.reshape(-1), all_preds_denorm.reshape(-1))\n",
    "    r2 = r2_score(all_targets_denorm.reshape(-1), all_preds_denorm.reshape(-1))\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss, mse, mae, r2, all_preds_denorm, all_targets_denorm\n",
    "\n",
    "# Función para probar el modelo con un ejemplo específico\n",
    "def test_model(model, input_data, scaler_input, scaler_target, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Normalizar el dato de entrada\n",
    "        input_np = input_data.numpy().reshape(-1, input_data.shape[-1])\n",
    "        input_normalized = scaler_input.transform(input_np).reshape(input_data.shape)\n",
    "        input_tensor = torch.tensor(input_normalized, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Hacer la predicción\n",
    "        if len(input_tensor.shape) == 2:  # Si es un solo ejemplo, agregar dimensión de batch\n",
    "            input_tensor = input_tensor.unsqueeze(0)\n",
    "        output = model(input_tensor)\n",
    "\n",
    "        # Desnormalizar la predicción\n",
    "        output_np = output.cpu().numpy()\n",
    "        output_denorm = scaler_target.inverse_transform(output_np.reshape(-1, output_np.shape[-1])).reshape(output_np.shape)\n",
    "        return output_denorm\n",
    "\n",
    "# Configuración\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hiperparámetros del modelo (AJUSTA ESTOS VALORES SEGÚN LOS MEJORES HIPERPARÁMETROS DE OPTUNA)\n",
    "# Reemplaza estos valores con los que obtuviste al entrenar el modelo\n",
    "# Hiperparámetros del modelo (AJUSTA ESTOS VALORES SEGÚN LOS DEL MODELO GUARDADO)\n",
    "# Reemplaza estos valores con los que obtuviste al entrenar el modelo\n",
    "d_model = 256              # <--- Cambiado de 128\n",
    "nhead = 4                  # Asumiendo que este no cambió, pero verifica si es necesario\n",
    "num_encoder_layers = 2     # <--- Cambiado de 3\n",
    "dim_feedforward = 256      # <--- Cambiado de 512\n",
    "dropout = 0.1              # Asumiendo que este no cambió, pero verifica si es necesario\n",
    "input_dim = 6              # Probablemente correcto\n",
    "output_dim = 4             # Probablemente correcto\n",
    "batch_size = 32            # Este afecta al DataLoader, no a la estructura del modelo\n",
    "\n",
    "# Cargar el modelo\n",
    "model_path = 'best_transformer_model.pth'\n",
    "model = load_model(model_path, input_dim, output_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout, device)\n",
    "\n",
    "# Crear DataLoader para los datos de validación (o prueba)\n",
    "# Asume que tienes val_input y val_target del código anterior\n",
    "val_dataset = TensorDataset(val_input, val_target)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Definir el criterio de pérdida\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Evaluar el modelo en los datos de validación\n",
    "avg_loss, mse, mae, r2, predictions, true_values = evaluate_model(model, val_loader, criterion, scaler_target, device)\n",
    "\n",
    "# Mostrar estadísticas\n",
    "print(\"Estadísticas del modelo en los datos de validación:\")\n",
    "print(f\"Pérdida promedio (MSE normalizado): {avg_loss:.4f}\")\n",
    "print(f\"Error Cuadrático Medio (MSE desnormalizado): {mse:.4f}\")\n",
    "print(f\"Error Absoluto Medio (MAE desnormalizado): {mae:.4f}\")\n",
    "print(f\"Coeficiente de Determinación (R² desnormalizado): {r2:.4f}\")\n",
    "\n",
    "# Probar el modelo con un ejemplo específico (por ejemplo, el primer escenario de validación)\n",
    "test_input = val_input[0]  # Primer escenario de validación\n",
    "predicted_output = test_model(model, test_input, scaler_input, scaler_target, device)\n",
    "true_output = scaler_target.inverse_transform(val_target[0].numpy().reshape(-1, val_target.shape[-1])).reshape(val_target[0].shape)\n",
    "\n",
    "# Mostrar los resultados de la prueba\n",
    "print(\"\\nPrueba con un ejemplo específico (primer escenario de validación):\")\n",
    "print(\"Predicciones (desnormalizadas) para los primeros 5 pares de relés:\")\n",
    "for i in range(min(74, predicted_output.shape[1])):  # Mostrar solo los primeros 5 pares\n",
    "    print(f\"Par {i+1}:\")\n",
    "    print(f\"  Predicción: {predicted_output[0, i, :]}\")\n",
    "    print(f\"  Valor real: {true_output[i, :]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
