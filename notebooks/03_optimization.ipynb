{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de automatización \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import string\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict, List, Any, Optional, Tuple, Set\n",
    "\n",
    "# --- Configuration ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "RELAY_PAIRS_PATH = \"/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/independent_relay_pairs_automation.json\"\n",
    "OPTIMIZED_SETTINGS_OUTPUT_PATH = \"/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/raw/optimized_relay_values.json\"\n",
    "\n",
    "\n",
    "# --- Constants ---\n",
    "K = 0.14\n",
    "N = 0.02\n",
    "CTI = 0.2\n",
    "# Optimization Bounds and Parameters\n",
    "MIN_TDS = 0.05 # Lower practical limit for TDS\n",
    "MAX_TDS = 1.0\n",
    "MIN_PICKUP = 0.05\n",
    "# Stricter pickup limit relative to Ishc, inspired by snippet\n",
    "MAX_PICKUP_FACTOR = 0.7 # Max pickup = Ishc * 0.7\n",
    "# MAX_TIME still needed for constraint violations, but not for calculation errors\n",
    "MAX_TIME = 20.0\n",
    "MAX_ITERATIONS = 250 # More iterations might be needed\n",
    "# Convergence Targets\n",
    "TARGET_TMT = -0.005 # Target for *total* miscoordination time (can stay negative)\n",
    "# ***MODIFIED: New threshold for individual Margin Time (MT)***\n",
    "MIN_ALLOWED_INDIVIDUAL_MT = -0.009 # Convergence threshold for the most negative individual MT\n",
    "CONVERGENCE_THRESHOLD_TMT = 0.005 # Smaller margin for TMT (still used for stagnation check)\n",
    "# Objective Function Weights\n",
    "W_TIME = 0.1 # Further decrease weight of total time\n",
    "W_MT = 15.0 # Increase weight for miscoordination penalty\n",
    "W_PICKUP_DIFF = 0.0 # Currently unused\n",
    "# Adjustment Step Sizes & Factors (Inspired by Snippet)\n",
    "AGGRESSIVE_MT_THRESHOLD = -CTI * 0.75 # Threshold to trigger aggressive adjustments\n",
    "# Aggressive Steps\n",
    "AGGRESSIVE_TDS_BACKUP_FACTOR = 1.15 # Increase backup TDS more\n",
    "AGGRESSIVE_TDS_MAIN_FACTOR = 0.90  # Decrease main TDS more\n",
    "AGGRESSIVE_PICKUP_BACKUP_FACTOR = 1.05 # Increase backup pickup if TDS maxed out\n",
    "# Normal Steps (additive for TDS, small mult for pickup)\n",
    "NORMAL_TDS_BACKUP_ADD = 0.02\n",
    "NORMAL_TDS_MAIN_SUB = 0.01\n",
    "NORMAL_PICKUP_BACKUP_FACTOR = 1.01 # Currently less emphasized\n",
    "NORMAL_PICKUP_MAIN_FACTOR = 0.99  # Currently less emphasized\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def load_json_file(file_path: str) -> Optional[Any]:\n",
    "    \"\"\"Loads data from a JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file: # Specify encoding\n",
    "            data = json.load(file)\n",
    "        logger.info(f\"Archivo cargado exitosamente: {file_path}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Error Crítico: Archivo no encontrado en la ruta especificada: {file_path}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Error Crítico: Formato JSON inválido en el archivo: {file_path}. Detalles: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error inesperado al cargar el archivo {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# MODIFIED: Returns Optional[float] - None indicates calculation error\n",
    "def calculate_operation_time(I_shc: float, I_pi: float, TDS: float) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Calculates relay operation time based on IEC standard curve.\n",
    "    Returns None if calculation inputs are invalid or lead to math errors.\n",
    "    Returns MAX_TIME if pickup constraint is violated or M <= 1.\n",
    "    \"\"\"\n",
    "    # Basic Input Validation / Conditions for non-calculation\n",
    "    if not (isinstance(I_shc, (int, float)) and I_shc > 0) or \\\n",
    "       not (isinstance(I_pi, (int, float)) and I_pi >= MIN_PICKUP) or \\\n",
    "       not (isinstance(TDS, (int, float)) and MIN_TDS <= TDS <= MAX_TDS):\n",
    "        # logger.debug(f\"Calc Error: Invalid input I_shc={I_shc}, I_pi={I_pi}, TDS={TDS}\")\n",
    "        return None # Return None for impossible basic inputs (e.g., non-positive Ishc, invalid TDS/pickup)\n",
    "\n",
    "    # Pickup Constraint Check (relative to Ishc)\n",
    "    # This check ensures the pickup setting is sensible relative to the fault current.\n",
    "    # If I_pi is too high relative to I_shc, the relay might not operate reliably or as intended.\n",
    "    # MAX_PICKUP_FACTOR defines this limit (e.g., 0.7 means pickup must be <= 70% of Ishc).\n",
    "    if I_pi > I_shc * MAX_PICKUP_FACTOR:\n",
    "        # logger.debug(f\"Calc Constraint Violation: Pickup I_pi={I_pi:.4f} > I_shc*factor={I_shc * MAX_PICKUP_FACTOR:.4f}\")\n",
    "        return MAX_TIME # Return MAX_TIME for pickup constraint violation\n",
    "\n",
    "    # Calculate M = I_shc / I_pi\n",
    "    # Check for division by zero (should be prevented by I_pi >= MIN_PICKUP > 0 check)\n",
    "    if I_pi <= 1e-9: # Avoid division by practically zero\n",
    "         # logger.debug(f\"Calc Error: Pickup near zero I_pi={I_pi}\")\n",
    "         return None\n",
    "\n",
    "    M = I_shc / I_pi\n",
    "\n",
    "    # Check for M <= 1.0 (relay should not operate for this fault current if M <= 1)\n",
    "    # This happens if the fault current is less than or equal to the pickup setting.\n",
    "    if M <= 1.0:\n",
    "        # logger.debug(f\"Non-operation: M={M:.4f} <= 1.0 (I_shc={I_shc:.2f}, I_pi={I_pi:.4f})\")\n",
    "        return MAX_TIME # Return MAX_TIME if M indicates non-operation\n",
    "\n",
    "    # Calculate Time using the IEC formula: T = TDS * (K / (M^N - 1))\n",
    "    try:\n",
    "        denominator = M**N - 1\n",
    "        # Check for near-zero denominator (M is guaranteed > 1 here)\n",
    "        if abs(denominator) < 1e-9:\n",
    "            # This case is less likely now M > 1 is enforced, but good practice.\n",
    "            # logger.debug(f\"Calc Error: Denominator near zero ({denominator}) for M={M:.4f}\")\n",
    "            return None # Return None for potential numerical instability\n",
    "\n",
    "        time = TDS * (K / denominator)\n",
    "\n",
    "        # Check for non-finite or non-positive results after calculation\n",
    "        if not np.isfinite(time) or time <= 0:\n",
    "            # logger.debug(f\"Calc Error: Result non-finite or non-positive ({time:.4f}) for M={M:.4f}, TDS={TDS:.4f}\")\n",
    "            return None # Return None for invalid calculation results\n",
    "\n",
    "        # Return the calculated time, capped by the maximum allowed time (MAX_TIME)\n",
    "        return min(time, MAX_TIME)\n",
    "\n",
    "    except (OverflowError, ValueError) as e:\n",
    "        # Catch potential math errors during M**N calculation\n",
    "        # logger.debug(f\"Calc Error: Math exception M={M:.4f}, N={N} -> {e}\")\n",
    "        return None # Return None on math errors\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected errors during calculation\n",
    "        logger.error(f\"Excepción inesperada en calculate_operation_time (I_shc={I_shc}, I_pi={I_pi}, TDS={TDS}): {e}\")\n",
    "        return None # Return None for safety\n",
    "\n",
    "def group_data_by_scenario(relay_pairs_data: List[Dict]) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Groups relay pair data by scenario_id and extracts initial settings.\"\"\"\n",
    "    scenario_map: Dict[str, Dict[str, Any]] = {}\n",
    "    processed_pairs_count = 0\n",
    "    skipped_pairs_count = 0\n",
    "    total_entries = len(relay_pairs_data)\n",
    "\n",
    "    logger.info(f\"Procesando {total_entries} entradas de pares de relés...\")\n",
    "\n",
    "    for i, pair_entry in enumerate(relay_pairs_data):\n",
    "        scenario_id = pair_entry.get(\"scenario_id\")\n",
    "        main_relay_info = pair_entry.get('main_relay')\n",
    "        backup_relay_info = pair_entry.get('backup_relay')\n",
    "\n",
    "        # Basic validation for entry structure\n",
    "        if not scenario_id or not isinstance(main_relay_info, dict) or not isinstance(backup_relay_info, dict):\n",
    "            # logger.warning(f\"Omitiendo entrada de par {i+1}/{total_entries}: Falta scenario_id o info de relé inválida.\")\n",
    "            skipped_pairs_count += 1\n",
    "            continue\n",
    "\n",
    "        if scenario_id not in scenario_map:\n",
    "            scenario_map[scenario_id] = {\n",
    "                \"pairs_info\": [],\n",
    "                \"initial_settings\": {}, # Store initial TDS/pickup here\n",
    "                \"relays\": set() # Keep track of all unique relays in the scenario\n",
    "            }\n",
    "\n",
    "        # Extract relay names and Ishc values\n",
    "        main_relay = main_relay_info.get('relay')\n",
    "        backup_relay = backup_relay_info.get('relay')\n",
    "        I_shc_main = main_relay_info.get('Ishc')\n",
    "        I_shc_backup = backup_relay_info.get('Ishc')\n",
    "\n",
    "        # Validate relay names and Ishc values (must be positive for calculations)\n",
    "        if not (main_relay and backup_relay and\n",
    "                isinstance(I_shc_main, (int, float)) and I_shc_main > 0 and\n",
    "                isinstance(I_shc_backup, (int, float)) and I_shc_backup > 0):\n",
    "            # logger.warning(f\"Omitiendo par {main_relay}/{backup_relay} en {scenario_id} (Entrada {i+1}): \"\n",
    "            #               f\"Falta nombre de relé o Ishc inválido/no positivo (Main: {I_shc_main}, Backup: {I_shc_backup}).\")\n",
    "            skipped_pairs_count += 1\n",
    "            continue\n",
    "\n",
    "        # Add unique relays to the set for this scenario\n",
    "        scenario_map[scenario_id]['relays'].add(main_relay)\n",
    "        scenario_map[scenario_id]['relays'].add(backup_relay)\n",
    "\n",
    "        # Extract and store initial settings (TDS, pickup) if not already stored\n",
    "        initial_settings_scenario = scenario_map[scenario_id]['initial_settings']\n",
    "        for r_name, r_info in [(main_relay, main_relay_info), (backup_relay, backup_relay_info)]:\n",
    "            if r_name not in initial_settings_scenario:\n",
    "                # Use .get() for safety, default to None if keys don't exist\n",
    "                tds = r_info.get('TDS')\n",
    "                # *** IMPORTANT: Input JSON uses 'pick_up', internal code uses 'pickup' ***\n",
    "                pickup = r_info.get('pick_up')\n",
    "\n",
    "                # Validate that TDS and pickup are numbers\n",
    "                if isinstance(tds, (int, float)) and isinstance(pickup, (int, float)):\n",
    "                    # Store with consistent internal keys\n",
    "                    initial_settings_scenario[r_name] = {\n",
    "                        'TDS_initial': float(tds),\n",
    "                        'pickup_initial': float(pickup) # Store the initial pickup value\n",
    "                    }\n",
    "                # else:\n",
    "                    # logger.warning(f\"({scenario_id}) Configuración inicial TDS/pickup no encontrada o inválida para el relé '{r_name}' en la entrada de par {i+1}. \"\n",
    "                    #              f\"Se usarán valores por defecto si es necesario más adelante.\")\n",
    "                    # Pass - default values will be handled in run_scenario_optimization\n",
    "\n",
    "        # Add processed pair information needed for optimization\n",
    "        scenario_map[scenario_id]['pairs_info'].append({\n",
    "            \"main_relay\": main_relay,\n",
    "            \"backup_relay\": backup_relay,\n",
    "            \"I_shc_main\": float(I_shc_main),\n",
    "            \"I_shc_backup\": float(I_shc_backup)\n",
    "        })\n",
    "        processed_pairs_count += 1\n",
    "\n",
    "    logger.info(f\"Datos agrupados por escenario. Total de entradas: {total_entries}, Pares procesados: {processed_pairs_count}, Pares omitidos: {skipped_pairs_count}\")\n",
    "    # Log scenarios found\n",
    "    if scenario_map:\n",
    "        logger.info(f\"Escenarios encontrados: {list(scenario_map.keys())}\")\n",
    "    else:\n",
    "        logger.warning(\"No se encontraron escenarios válidos después del procesamiento.\")\n",
    "\n",
    "    return scenario_map\n",
    "\n",
    "\n",
    "# --- Scenario-Specific Optimization Function (MODIFIED for None handling, new convergence, AND INITIAL PICKUP CHECK) ---\n",
    "def run_scenario_optimization(\n",
    "    scenario_id: str,\n",
    "    pairs_info: List[Dict],\n",
    "    initial_settings: Dict[str, Dict[str, float]], # Contains TDS_initial, pickup_initial\n",
    "    relays_in_scenario: Set[str]\n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Performs iterative optimization for a single scenario.\n",
    "    Handles calculation errors (None), excludes errors from TMT calculation,\n",
    "    uses the new individual MT convergence threshold (-0.009),\n",
    "    AND enforces the initial pickup < min(Ishc) constraint.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(f\"--- Iniciando optimización para Escenario: {scenario_id} ---\")\n",
    "    if not pairs_info:\n",
    "        logger.warning(f\"({scenario_id}) No hay pares válidos para procesar. Omitiendo optimización.\")\n",
    "        return {}\n",
    "    if not relays_in_scenario:\n",
    "        logger.warning(f\"({scenario_id}) No hay relés definidos para el escenario. Omitiendo optimización.\")\n",
    "        return {}\n",
    "\n",
    "    # --- ADDED: Pre-calculate minimum Ishc for each relay in this scenario ---\n",
    "    # This helps enforce the condition pickup < Ishc for initial settings.\n",
    "    min_ishc_per_relay: Dict[str, float] = {}\n",
    "    for pair in pairs_info:\n",
    "        main_relay = pair[\"main_relay\"]\n",
    "        backup_relay = pair[\"backup_relay\"]\n",
    "        # Use .get with a default of 0 to handle potential missing keys safely\n",
    "        ishc_main = pair.get(\"I_shc_main\", 0.0)\n",
    "        ishc_backup = pair.get(\"I_shc_backup\", 0.0)\n",
    "\n",
    "        # Store the minimum positive Ishc seen by each relay\n",
    "        if ishc_main > 0:\n",
    "             min_ishc_per_relay[main_relay] = min(min_ishc_per_relay.get(main_relay, float('inf')), ishc_main)\n",
    "        if ishc_backup > 0:\n",
    "             min_ishc_per_relay[backup_relay] = min(min_ishc_per_relay.get(backup_relay, float('inf')), ishc_backup)\n",
    "    # --- END ADDED SECTION ---\n",
    "\n",
    "\n",
    "    # 1. Initialize settings - Start with MIN_TDS. Use initial Pickup from input,\n",
    "    #    but adjust it if it violates pickup < min(Ishc) constraint.\n",
    "    relay_settings: Dict[str, Dict[str, float]] = {}\n",
    "    default_pickup = MIN_PICKUP * 1.5 # A sensible default if initial pickup is missing\n",
    "    PICKUP_ADJUSTMENT_FACTOR = 0.99 # Factor to set pickup just below Ishc if needed (Ishc * 0.99)\n",
    "\n",
    "    logger.info(f\"({scenario_id}) Inicializando ajustes para {len(relays_in_scenario)} relés...\")\n",
    "    for relay in relays_in_scenario:\n",
    "        # Determine the initial pickup value to use\n",
    "        initial_pickup_val = default_pickup # Assume default initially\n",
    "        relay_has_initial = relay in initial_settings and 'pickup_initial' in initial_settings[relay]\n",
    "\n",
    "        if relay_has_initial:\n",
    "            # Use the value from the input file\n",
    "            initial_pickup_val = initial_settings[relay]['pickup_initial']\n",
    "            # Basic validation for the loaded value\n",
    "            if not isinstance(initial_pickup_val, (int, float)) or initial_pickup_val <= 0:\n",
    "                 logger.warning(f\"({scenario_id}) Pickup inicial inválido ({initial_pickup_val}) para relé '{relay}'. Usando defecto: {default_pickup:.4f}\")\n",
    "                 initial_pickup_val = default_pickup\n",
    "        else:\n",
    "             # Log warning only if the relay was expected to have settings (i.e., it was in pairs_info)\n",
    "             logger.warning(f\"({scenario_id}) Configuración inicial de Pickup no encontrada para relé '{relay}'. Usando defecto: {default_pickup:.4f}\")\n",
    "\n",
    "        # Ensure the starting pickup is at least MIN_PICKUP before checking against Ishc\n",
    "        current_pickup = max(MIN_PICKUP, initial_pickup_val)\n",
    "\n",
    "        # Get the minimum Ishc this relay sees in this scenario (if any)\n",
    "        min_ishc_relay = min_ishc_per_relay.get(relay) # Returns None if relay wasn't found or had no positive Ishc\n",
    "\n",
    "        if min_ishc_relay is not None and min_ishc_relay > 0:\n",
    "            # Check if pickup >= min_Ishc (violates Ishc / pickup > 1)\n",
    "            if current_pickup >= min_ishc_relay:\n",
    "                # Adjust pickup to be slightly less than the minimum Ishc\n",
    "                adjusted_pickup = min_ishc_relay * PICKUP_ADJUSTMENT_FACTOR\n",
    "                # Ensure the adjusted value doesn't go below the absolute minimum pickup\n",
    "                adjusted_pickup = max(MIN_PICKUP, adjusted_pickup)\n",
    "\n",
    "                # Log the adjustment clearly\n",
    "                logger.warning(\n",
    "                    f\"({scenario_id}) AJUSTE INICIAL DE PICKUP para relé '{relay}': \"\n",
    "                    f\"Pickup inicial ({current_pickup:.4f}) era >= Min Ishc ({min_ishc_relay:.4f}). \"\n",
    "                    f\"Ajustado a -> {adjusted_pickup:.4f}.\"\n",
    "                )\n",
    "                current_pickup = adjusted_pickup # Use the adjusted value\n",
    "            # else: # Pickup is already < min_Ishc, which is good.\n",
    "               # logger.debug(f\"({scenario_id}) Verificación Inicial OK para relé '{relay}': Pickup ({current_pickup:.4f}) < Min Ishc ({min_ishc_relay:.4f}).\")\n",
    "\n",
    "        # else: # No valid minimum Ishc found for this relay. Cannot perform the check.\n",
    "            # logger.debug(f\"({scenario_id}) No se encontró Ishc mínimo válido (>0) para el relé '{relay}'. No se realizó verificación inicial pickup < Ishc.\")\n",
    "\n",
    "        # Assign the final calculated initial pickup and the minimum TDS\n",
    "        relay_settings[relay] = {\n",
    "            \"TDS\": MIN_TDS,        # Start all relays at minimum TDS\n",
    "            \"pickup\": current_pickup # Use the original or adjusted pickup\n",
    "        }\n",
    "        # logger.debug(f\"({scenario_id}) Relé '{relay}' inicializado: TDS={relay_settings[relay]['TDS']:.4f}, Pickup={relay_settings[relay]['pickup']:.4f}\")\n",
    "\n",
    "    # --- Optimization Loop ---\n",
    "    last_tmt = float('inf') # Track Total Miscoordination Time of previous iteration\n",
    "    no_improvement_streak = 0 # Counter for consecutive iterations with negligible TMT improvement\n",
    "    CONVERGENCE_STREAK_LIMIT = 25 # Number of iterations without improvement to trigger stop\n",
    "\n",
    "    logger.info(f\"({scenario_id}) Iniciando bucle de optimización (max {MAX_ITERATIONS} iteraciones)...\")\n",
    "    for iteration in range(MAX_ITERATIONS):\n",
    "        total_main_time = 0.0       # Sum of valid main relay operation times\n",
    "        tmt = 0.0                   # Total Miscoordination Time (sum of negative MTs)\n",
    "        miscoordination_penalty = 0.0 # Sum of squared negative MTs (for objective function)\n",
    "        current_pair_results = []   # Store results for each pair in this iteration\n",
    "        max_neg_mt = 0.0            # Track the most negative Margin Time found in this iteration (closest to 0 is better)\n",
    "        error_pairs_count = 0       # Count pairs where time calculation failed (returned None)\n",
    "        violated_pairs_count = 0    # Count pairs where at least one time was MAX_TIME\n",
    "\n",
    "        # --- Step 1: Calculate performance for all pairs with current settings ---\n",
    "        for pair in pairs_info:\n",
    "            main_relay = pair[\"main_relay\"]\n",
    "            backup_relay = pair[\"backup_relay\"]\n",
    "            I_shc_main = pair[\"I_shc_main\"]\n",
    "            I_shc_backup = pair[\"I_shc_backup\"]\n",
    "\n",
    "            # Get current settings (should always exist after initialization)\n",
    "            if main_relay not in relay_settings or backup_relay not in relay_settings:\n",
    "                logger.error(f\"({scenario_id}) Iter {iteration+1}: ¡Error Interno! Falta configuración para {main_relay} o {backup_relay}. Omitiendo par.\")\n",
    "                error_pairs_count += 1\n",
    "                continue # Should not happen\n",
    "\n",
    "            tds_main = relay_settings[main_relay][\"TDS\"]\n",
    "            pickup_main = relay_settings[main_relay][\"pickup\"]\n",
    "            tds_backup = relay_settings[backup_relay][\"TDS\"]\n",
    "            pickup_backup = relay_settings[backup_relay][\"pickup\"]\n",
    "\n",
    "            # Pickup values are already bounded by MIN_PICKUP during initialization and adjustment.\n",
    "            # The MAX_PICKUP_FACTOR constraint is checked *inside* calculate_operation_time.\n",
    "\n",
    "            # Calculate operation times for main and backup relays\n",
    "            main_time = calculate_operation_time(I_shc_main, pickup_main, tds_main)\n",
    "            backup_time = calculate_operation_time(I_shc_backup, pickup_backup, tds_backup)\n",
    "\n",
    "            delta_t: Optional[float] = None # Time difference (Backup - Main)\n",
    "            mt: Optional[float] = None      # Margin Time (delta_t - CTI)\n",
    "\n",
    "            pair_status = \"OK\" # Track status for logging/debugging\n",
    "\n",
    "            # --- Process results: Check for calculation errors or constraint violations ---\n",
    "            if main_time is None or backup_time is None:\n",
    "                # Case 1: Calculation Error (e.g., invalid inputs, math error)\n",
    "                delta_t = None\n",
    "                mt = None\n",
    "                error_pairs_count += 1\n",
    "                pair_status = \"ERROR_CALC\"\n",
    "                # logger.debug(f\"({scenario_id}) Iter {iteration+1}: Error cálculo par {main_relay}({main_time})/{backup_relay}({backup_time})\")\n",
    "\n",
    "            elif main_time >= MAX_TIME or backup_time >= MAX_TIME:\n",
    "                # Case 2: Constraint Violation or Non-operation (Pickup too high, M<=1)\n",
    "                # Assign a large penalty value to MT to indicate a severe issue, but don't use None.\n",
    "                # This distinguishes it from a calculation error and ensures the pair is penalized.\n",
    "                delta_t = MAX_TIME # Indicate violation in delta_t as well\n",
    "                mt = -MAX_TIME * 2 # Use a large negative penalty for MT\n",
    "                violated_pairs_count += 1\n",
    "                pair_status = \"VIOLATION_MAX_TIME\"\n",
    "                # Treat this as a severe miscoordination for adjustment purposes.\n",
    "                # logger.debug(f\"({scenario_id}) Iter {iteration+1}: MAX_TIME detectado {main_relay}({main_time})/{backup_relay}({backup_time}) -> mt={mt:.1f}\")\n",
    "\n",
    "            else:\n",
    "                # Case 3: Valid finite times calculated\n",
    "                delta_t = backup_time - main_time\n",
    "                mt = delta_t - CTI\n",
    "                pair_status = \"OK\" # Or \"MISCOORD\" if mt < 0\n",
    "\n",
    "            # Store results for this pair\n",
    "            current_pair_results.append({\n",
    "                \"main_relay\": main_relay, \"backup_relay\": backup_relay,\n",
    "                \"I_shc_main\": I_shc_main, \"I_shc_backup\": I_shc_backup,\n",
    "                \"main_time\": main_time, \"backup_time\": backup_time, # Can be None, float, or MAX_TIME\n",
    "                \"delta_t\": delta_t,     # Can be None, float, or MAX_TIME\n",
    "                \"mt\": mt,               # Can be None, float, or large negative penalty\n",
    "                \"status\": pair_status\n",
    "            })\n",
    "\n",
    "            # --- Accumulate performance metrics (only use valid, finite, non-violated results) ---\n",
    "            # Add main time to total only if it's a valid, finite time < MAX_TIME\n",
    "            if main_time is not None and main_time < MAX_TIME:\n",
    "                total_main_time += main_time\n",
    "\n",
    "            # Add to TMT, penalty, and track max_neg_mt ONLY if mt is a valid negative float\n",
    "            # Exclude None (calc errors) and the large negative penalty (MAX_TIME violations)\n",
    "            if mt is not None and mt < 0 and mt > -MAX_TIME: # Check mt is negative AND not the large penalty\n",
    "                tmt += mt\n",
    "                miscoordination_penalty += mt**2 # Penalize quadratically\n",
    "                max_neg_mt = min(max_neg_mt, mt) # Update the most negative MT found so far\n",
    "\n",
    "        # --- Step 2: Calculate Objective Function ---\n",
    "        # OF = Penalty for Miscoordination + Penalty for Total Operation Time\n",
    "        of = W_MT * miscoordination_penalty + W_TIME * total_main_time\n",
    "\n",
    "        # Log progress periodically or if miscoordination is significant\n",
    "        if (iteration + 1) % 25 == 0 or iteration == 0 or max_neg_mt < MIN_ALLOWED_INDIVIDUAL_MT :\n",
    "             logger.info(\n",
    "                 f\"({scenario_id}) Iter {iteration+1}/{MAX_ITERATIONS}: OF={of:.4f}, \"\n",
    "                 f\"TMT={tmt:.4f}, MaxNegMT={max_neg_mt:.4f} (Target>={MIN_ALLOWED_INDIVIDUAL_MT:.4f}), \"\n",
    "                 f\"CalcErrors={error_pairs_count}, Violations={violated_pairs_count}\"\n",
    "             )\n",
    "\n",
    "        # --- Step 3: Check Convergence ---\n",
    "        # Converge if total miscoordination is near zero AND the worst individual miscoordination is acceptable.\n",
    "        # Using TMT >= TARGET_TMT can be tricky if TARGET_TMT is negative. Let's focus on max_neg_mt.\n",
    "        if max_neg_mt >= MIN_ALLOWED_INDIVIDUAL_MT:\n",
    "            logger.info(\n",
    "                f\"({scenario_id}) *** Convergencia Alcanzada en Iteración {iteration + 1} ***\\n\"\n",
    "                f\"    TMT Final = {tmt:.4f} (Target TMT >= {TARGET_TMT})\\n\"\n",
    "                f\"    Peor MT Individual = {max_neg_mt:.4f} (Target >= {MIN_ALLOWED_INDIVIDUAL_MT})\"\n",
    "            )\n",
    "            break # Exit optimization loop\n",
    "\n",
    "        # --- Step 4: Adjust Relay Settings if Not Converged ---\n",
    "        adjustments_made = False\n",
    "        # Create a copy of current settings to modify; apply changes at the end\n",
    "        next_relay_settings = copy.deepcopy(relay_settings)\n",
    "\n",
    "        # Iterate through pairs that need adjustment (miscoordinated or violated)\n",
    "        for pair_res in current_pair_results:\n",
    "            # Skip pairs with calculation errors (mt is None) or already coordinated (mt >= 0)\n",
    "            if pair_res[\"mt\"] is None or pair_res[\"mt\"] >= 0:\n",
    "                continue\n",
    "\n",
    "            # Adjust pairs where mt < 0 (including the large negative penalty for MAX_TIME cases)\n",
    "            main_relay = pair_res[\"main_relay\"]; backup_relay = pair_res[\"backup_relay\"]\n",
    "            I_shc_main = pair_res[\"I_shc_main\"]; I_shc_backup = pair_res[\"I_shc_backup\"]\n",
    "            mt_val = pair_res[\"mt\"] # This is a negative float or the large negative penalty\n",
    "\n",
    "            # Get current settings from the *next* settings dict (in case of multiple adjustments)\n",
    "            tds_main_curr = next_relay_settings[main_relay][\"TDS\"]\n",
    "            tds_backup_curr = next_relay_settings[backup_relay][\"TDS\"]\n",
    "            pickup_main_curr = next_relay_settings[main_relay][\"pickup\"]\n",
    "            pickup_backup_curr = next_relay_settings[backup_relay][\"pickup\"]\n",
    "\n",
    "            # Initialize new values with current ones\n",
    "            new_tds_backup = tds_backup_curr\n",
    "            new_pickup_backup = pickup_backup_curr\n",
    "            new_tds_main = tds_main_curr\n",
    "            new_pickup_main = pickup_main_curr\n",
    "\n",
    "            adjustment_type = \"Normal\" # Default adjustment type\n",
    "\n",
    "            # Apply adjustments based on severity (mt_val vs AGGRESSIVE_MT_THRESHOLD)\n",
    "            # The large negative penalty (-MAX_TIME*2) will always trigger aggressive adjustment.\n",
    "            if mt_val < AGGRESSIVE_MT_THRESHOLD:\n",
    "                adjustment_type = \"Aggressive\"\n",
    "                # Increase Backup TDS (make it slower)\n",
    "                new_tds_backup = tds_backup_curr * AGGRESSIVE_TDS_BACKUP_FACTOR\n",
    "                # Decrease Main TDS (make it faster)\n",
    "                new_tds_main = tds_main_curr * AGGRESSIVE_TDS_MAIN_FACTOR\n",
    "\n",
    "                # Aggressive Pickup Adjustment (if TDS hits limits):\n",
    "                # If backup TDS maxed out, try increasing backup pickup (makes it slower/less sensitive)\n",
    "                if abs(min(MAX_TDS, new_tds_backup) - MAX_TDS) < 1e-6:\n",
    "                    max_allowed_pickup_backup = I_shc_backup * MAX_PICKUP_FACTOR # Respect constraint\n",
    "                    new_pickup_backup = pickup_backup_curr * AGGRESSIVE_PICKUP_BACKUP_FACTOR\n",
    "                    new_pickup_backup = min(max_allowed_pickup_backup, max(MIN_PICKUP, new_pickup_backup)) # Apply bounds\n",
    "\n",
    "                # Optional: Aggressively decrease main pickup if main TDS hits min? Less common.\n",
    "                # if abs(max(MIN_TDS, new_tds_main) - MIN_TDS) < 1e-6:\n",
    "                #     max_allowed_pickup_main = I_shc_main * MAX_PICKUP_FACTOR\n",
    "                #     new_pickup_main = pickup_main_curr * 0.98 # Example factor\n",
    "                #     new_pickup_main = min(max_allowed_pickup_main, max(MIN_PICKUP, new_pickup_main))\n",
    "\n",
    "            else: # Normal adjustment (mt is negative but not severely)\n",
    "                adjustment_type = \"Normal\"\n",
    "                # Additive adjustments for TDS\n",
    "                new_tds_backup = tds_backup_curr + NORMAL_TDS_BACKUP_ADD\n",
    "                new_tds_main = tds_main_curr - NORMAL_TDS_MAIN_SUB\n",
    "\n",
    "                # Subtle pickup adjustments (less critical now with checks in calc_time and init)\n",
    "                # These factors have less impact compared to TDS adjustments.\n",
    "                # max_allowed_pickup_backup = I_shc_backup * MAX_PICKUP_FACTOR\n",
    "                # new_pickup_backup = pickup_backup_curr * NORMAL_PICKUP_BACKUP_FACTOR\n",
    "                # new_pickup_backup = min(max_allowed_pickup_backup, max(MIN_PICKUP, new_pickup_backup))\n",
    "                # max_allowed_pickup_main = I_shc_main * MAX_PICKUP_FACTOR\n",
    "                # new_pickup_main = pickup_main_curr * NORMAL_PICKUP_MAIN_FACTOR\n",
    "                # new_pickup_main = min(max_allowed_pickup_main, max(MIN_PICKUP, new_pickup_main))\n",
    "\n",
    "\n",
    "            # --- Apply and Bound Adjustments ---\n",
    "            # Apply bounds (MIN/MAX TDS, MIN/MAX Pickup) immediately after calculation\n",
    "            # Backup Relay: Increase time (Increase TDS or Pickup)\n",
    "            next_relay_settings[backup_relay][\"TDS\"] = min(MAX_TDS, max(MIN_TDS, new_tds_backup))\n",
    "            max_pickup_b = I_shc_backup * MAX_PICKUP_FACTOR # Max pickup constraint for backup\n",
    "            next_relay_settings[backup_relay][\"pickup\"] = min(max_pickup_b, max(MIN_PICKUP, new_pickup_backup))\n",
    "\n",
    "            # Main Relay: Decrease time (Decrease TDS or Pickup)\n",
    "            next_relay_settings[main_relay][\"TDS\"] = min(MAX_TDS, max(MIN_TDS, new_tds_main))\n",
    "            max_pickup_m = I_shc_main * MAX_PICKUP_FACTOR # Max pickup constraint for main\n",
    "            next_relay_settings[main_relay][\"pickup\"] = min(max_pickup_m, max(MIN_PICKUP, new_pickup_main))\n",
    "\n",
    "            # Log the specific adjustment made (optional, can be verbose)\n",
    "            # logger.debug(\n",
    "            #     f\"({scenario_id}) Iter {iteration+1}: Ajuste {adjustment_type} para {main_relay}/{backup_relay} (mt={mt_val:.4f})\\n\"\n",
    "            #     f\"  Backup: TDS {tds_backup_curr:.4f}->{next_relay_settings[backup_relay]['TDS']:.4f}, \"\n",
    "            #     f\"Pickup {pickup_backup_curr:.4f}->{next_relay_settings[backup_relay]['pickup']:.4f}\\n\"\n",
    "            #     f\"  Main:   TDS {tds_main_curr:.4f}->{next_relay_settings[main_relay]['TDS']:.4f}, \"\n",
    "            #     f\"Pickup {pickup_main_curr:.4f}->{next_relay_settings[main_relay]['pickup']:.4f}\"\n",
    "            # )\n",
    "\n",
    "            adjustments_made = True\n",
    "        # --- End of Adjustment Loop for Pairs ---\n",
    "\n",
    "        if adjustments_made:\n",
    "            relay_settings = next_relay_settings # Apply the adjusted settings for the next iteration\n",
    "        elif iteration > 15: # Stop if no adjustments were needed after an initial settling period\n",
    "             logger.info(f\"({scenario_id}) No se realizaron ajustes en iteración {iteration + 1} (después de iter 15). Deteniendo por estabilidad.\")\n",
    "             break\n",
    "\n",
    "        # --- Step 5: Check for Stagnation (based on TMT improvement) ---\n",
    "        # Use the original CONVERGENCE_THRESHOLD_TMT for stagnation check magnitude.\n",
    "        # Check if the absolute improvement in TMT is negligible.\n",
    "        if abs(tmt - last_tmt) < CONVERGENCE_THRESHOLD_TMT:\n",
    "            no_improvement_streak += 1\n",
    "        else:\n",
    "            no_improvement_streak = 0 # Reset streak if there was improvement\n",
    "\n",
    "        last_tmt = tmt # Update last TMT for the next iteration's check\n",
    "\n",
    "        # Stop if TMT hasn't improved significantly for several iterations\n",
    "        if no_improvement_streak >= CONVERGENCE_STREAK_LIMIT:\n",
    "            logger.warning(\n",
    "                f\"({scenario_id}) Detenido por Estancamiento: TMT ({tmt:.4f}) no mejoró significativamente \"\n",
    "                f\"durante {no_improvement_streak} iteraciones (umbral < {CONVERGENCE_THRESHOLD_TMT}).\"\n",
    "            )\n",
    "            logger.warning(f\"({scenario_id}) Estado final: MaxNegMT={max_neg_mt:.4f} (Target>={MIN_ALLOWED_INDIVIDUAL_MT:.4f})\")\n",
    "            break\n",
    "\n",
    "    # --- End of Main Optimization Loop ---\n",
    "\n",
    "    else: # This block executes if the loop finished without 'break' (MAX_ITERATIONS reached)\n",
    "        logger.warning(\n",
    "            f\"({scenario_id}) Optimización finalizada por alcanzar MAX_ITERATIONS ({MAX_ITERATIONS}). \"\n",
    "            f\"La convergencia ({MIN_ALLOWED_INDIVIDUAL_MT:.4f}) pudo no haberse alcanzado.\"\n",
    "        )\n",
    "        # Log the final state\n",
    "        logger.warning(f\"({scenario_id}) Estado final: TMT={tmt:.4f}, MaxNegMT={max_neg_mt:.4f}, Errores={error_pairs_count}, Violaciones={violated_pairs_count}\")\n",
    "\n",
    "\n",
    "    # --- Step 6: Format and Return Final Optimized Settings ---\n",
    "    logger.info(f\"({scenario_id}) Formateando resultados finales...\")\n",
    "    formatted_settings = {}\n",
    "\n",
    "    # Recalculate max Ishc per relay for final bounding (optional, but good practice)\n",
    "    # Ensures final pickup isn't higher than factor*Ishc for the highest current it saw.\n",
    "    # This was already handled during adjustments, but this is a final check.\n",
    "    relays_max_ishc = {}\n",
    "    for relay in relays_in_scenario:\n",
    "        max_ishc_relay = 0\n",
    "        for p in pairs_info:\n",
    "            if p['main_relay'] == relay: max_ishc_relay = max(max_ishc_relay, p.get('I_shc_main', 0))\n",
    "            if p['backup_relay'] == relay: max_ishc_relay = max(max_ishc_relay, p.get('I_shc_backup', 0))\n",
    "        # Provide a fallback Ishc if none found (e.g., based on default pickup)\n",
    "        relays_max_ishc[relay] = max_ishc_relay if max_ishc_relay > 0 else (default_pickup / MIN_PICKUP) * 1.5 # Heuristic fallback\n",
    "\n",
    "\n",
    "    for relay, settings in relay_settings.items():\n",
    "        final_tds = settings['TDS']\n",
    "        final_pickup = settings['pickup']\n",
    "        max_ishc_for_final_bound = relays_max_ishc.get(relay, (default_pickup / MIN_PICKUP) * 1.5)\n",
    "\n",
    "        # Apply final bounds: MIN/MAX TDS, MIN_PICKUP, and MAX_PICKUP_FACTOR * max_Ishc\n",
    "        final_tds_bounded = min(MAX_TDS, max(MIN_TDS, final_tds))\n",
    "        max_allowed_pickup_final = max_ishc_for_final_bound * MAX_PICKUP_FACTOR\n",
    "        final_pickup_bounded = min(max_allowed_pickup_final, max(MIN_PICKUP, final_pickup))\n",
    "\n",
    "        # Check if final bounding significantly changed values (optional logging)\n",
    "        # if abs(final_tds_bounded - final_tds) > 1e-5 or abs(final_pickup_bounded - final_pickup) > 1e-5:\n",
    "        #     logger.debug(f\"({scenario_id}) Final bounding applied to '{relay}': \"\n",
    "        #                 f\"TDS {final_tds:.5f}->{final_tds_bounded:.5f}, \"\n",
    "        #                 f\"Pickup {final_pickup:.5f}->{final_pickup_bounded:.5f}\")\n",
    "\n",
    "        # Format to 5 decimal places\n",
    "        formatted_settings[relay] = {\n",
    "            \"TDS\": float(f\"{final_tds_bounded:.5f}\"),\n",
    "            \"pickup\": float(f\"{final_pickup_bounded:.5f}\")\n",
    "        }\n",
    "\n",
    "    logger.info(f\"--- Optimización Finalizada para Escenario: {scenario_id} ---\")\n",
    "    return formatted_settings\n",
    "\n",
    "\n",
    "# --- Script Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"--- Iniciando Script de Optimización de Ajustes de Relés (v5 - Pickup Init Check & MT Threshold -0.009) ---\")\n",
    "\n",
    "    # --- 1. Load Input Data ---\n",
    "    logger.info(f\"Cargando pares de relés desde: {RELAY_PAIRS_PATH}\")\n",
    "    if not os.path.exists(RELAY_PAIRS_PATH):\n",
    "        logger.error(f\"¡Error Crítico! No se encontró el archivo de entrada: {RELAY_PAIRS_PATH}\")\n",
    "        raise SystemExit(\"Script detenido: Archivo de pares de relés no encontrado.\")\n",
    "\n",
    "    relay_pairs_data = load_json_file(RELAY_PAIRS_PATH)\n",
    "    if relay_pairs_data is None or not isinstance(relay_pairs_data, list):\n",
    "        logger.error(\"Error Crítico: El archivo de entrada está vacío, no es una lista JSON válida o no se pudo cargar.\")\n",
    "        raise SystemExit(\"Script detenido: Error al cargar datos de entrada.\")\n",
    "    if not relay_pairs_data:\n",
    "        logger.error(\"Error Crítico: El archivo de entrada JSON está vacío.\")\n",
    "        raise SystemExit(\"Script detenido: No hay datos de pares de relés para procesar.\")\n",
    "\n",
    "\n",
    "    # --- 2. Group Data by Scenario ---\n",
    "    logger.info(\"Agrupando datos por escenario...\")\n",
    "    scenario_data_map = group_data_by_scenario(relay_pairs_data)\n",
    "\n",
    "    if not scenario_data_map:\n",
    "        logger.error(\"Error Crítico: No se pudieron agrupar los datos o no se encontraron escenarios/pares válidos después del procesamiento inicial.\")\n",
    "        raise SystemExit(\"Script detenido: No hay escenarios válidos para optimizar.\")\n",
    "\n",
    "\n",
    "    # --- 3. Run Optimization for Each Scenario ---\n",
    "    all_optimized_settings: Dict[str, Dict[str, Dict[str, float]]] = {}\n",
    "    successful_scenarios = 0\n",
    "    failed_scenarios = 0\n",
    "\n",
    "    logger.info(f\"Iniciando optimización para {len(scenario_data_map)} escenarios encontrados...\")\n",
    "    for scenario_id, scenario_data in scenario_data_map.items():\n",
    "        # Validate scenario data before processing\n",
    "        if not scenario_data.get('relays') or not scenario_data.get('pairs_info'):\n",
    "             logger.warning(f\"Omitiendo escenario '{scenario_id}': No contiene relés o pares de información válidos después del agrupamiento.\")\n",
    "             failed_scenarios += 1\n",
    "             continue\n",
    "\n",
    "        try:\n",
    "            optimized_settings_for_scenario = run_scenario_optimization(\n",
    "                scenario_id,\n",
    "                scenario_data['pairs_info'],\n",
    "                scenario_data['initial_settings'],\n",
    "                scenario_data['relays']\n",
    "            )\n",
    "\n",
    "            if optimized_settings_for_scenario:\n",
    "                all_optimized_settings[scenario_id] = optimized_settings_for_scenario\n",
    "                successful_scenarios += 1\n",
    "                logger.info(f\"Optimización para escenario '{scenario_id}' completada exitosamente.\")\n",
    "            else:\n",
    "                logger.warning(f\"La optimización no produjo resultados válidos para el escenario: {scenario_id}\")\n",
    "                failed_scenarios += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error Inesperado durante la optimización del escenario '{scenario_id}': {e}\", exc_info=True) # Log traceback\n",
    "            failed_scenarios += 1\n",
    "            # Continue to the next scenario if one fails\n",
    "\n",
    "    # --- 4. Format and Save Results ---\n",
    "    logger.info(\"--- Resumen de Optimización ---\")\n",
    "    logger.info(f\"Escenarios procesados exitosamente: {successful_scenarios}\")\n",
    "    logger.info(f\"Escenarios fallidos u omitidos: {failed_scenarios}\")\n",
    "\n",
    "    output_list = []\n",
    "    if all_optimized_settings:\n",
    "        logger.info(\"Formateando resultados optimizados en la estructura de lista deseada...\")\n",
    "        for scenario_id, optimized_settings in all_optimized_settings.items():\n",
    "            # Generate a timestamp for the results\n",
    "            current_timestamp = datetime.now(timezone.utc).isoformat(timespec='microseconds').replace('+00:00', 'Z') # ISO 8601 format with Z\n",
    "\n",
    "            list_entry = {\n",
    "                # \"_id\": { \"$oid\": generated_oid }, # Uncomment if MongoDB OID structure is needed\n",
    "                \"scenario_id\": scenario_id,\n",
    "                \"timestamp\": current_timestamp,\n",
    "                \"relay_values\": optimized_settings # Contains optimized {'RelayName': {'TDS': x, 'pickup': y}}\n",
    "            }\n",
    "            output_list.append(list_entry)\n",
    "        logger.info(f\"Formato de lista creado con {len(output_list)} escenarios optimizados.\")\n",
    "\n",
    "        # --- 5. Save the results to JSON file ---\n",
    "        try:\n",
    "            # Ensure the output directory exists\n",
    "            output_dir = os.path.dirname(OPTIMIZED_SETTINGS_OUTPUT_PATH)\n",
    "            if output_dir and not os.path.exists(output_dir):\n",
    "                logger.info(f\"Creando directorio de salida: {output_dir}\")\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            # Write the list of results to the output JSON file\n",
    "            # Use allow_nan=False to ensure standard JSON compatibility (NaN/Infinity are not valid)\n",
    "            # Python's None will be converted to JSON null, which is standard.\n",
    "            with open(OPTIMIZED_SETTINGS_OUTPUT_PATH, 'w', encoding='utf-8') as file:\n",
    "                json.dump(output_list, file, indent=2, allow_nan=False)\n",
    "            logger.info(f\"Archivo con ajustes optimizados guardado exitosamente en: {OPTIMIZED_SETTINGS_OUTPUT_PATH}\")\n",
    "\n",
    "        except IOError as e:\n",
    "             logger.error(f\"Error de E/S al intentar guardar el archivo de salida {OPTIMIZED_SETTINGS_OUTPUT_PATH}: {e}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error inesperado al guardar el archivo de salida {OPTIMIZED_SETTINGS_OUTPUT_PATH}: {e}\")\n",
    "\n",
    "    elif successful_scenarios == 0:\n",
    "         logger.error(\"La optimización no produjo resultados exitosos para ningún escenario. No se guardó ningún archivo de salida.\")\n",
    "    else:\n",
    "         # This case shouldn't happen if successful_scenarios > 0, but included for completeness\n",
    "         logger.warning(\"No se encontraron ajustes optimizados para guardar, aunque algunos escenarios se completaron (revisar logs).\")\n",
    "\n",
    "\n",
    "    logger.info(\"--- Script de Optimización Finalizado ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
