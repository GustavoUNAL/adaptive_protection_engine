{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eb5a7f1",
   "metadata": {},
   "source": [
    "# Crea estructura de datos pares de relays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1952d48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos base desde: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/raw/data_coordination.json\n",
      "Datos base cargados y pre-procesados para 68 escenarios.\n",
      "Cargando valores de relés desde: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/raw/optimized_relay_values.json\n",
      "Valores de relés cargados para 68 escenarios.\n",
      "Procesando escenarios para crear pares de relés independientes...\n",
      "Procesando escenario: scenario_1\n",
      "Procesando escenario: scenario_2\n",
      "Procesando escenario: scenario_3\n",
      "Procesando escenario: scenario_4\n",
      "Procesando escenario: scenario_5\n",
      "Procesando escenario: scenario_6\n",
      "Procesando escenario: scenario_7\n",
      "Procesando escenario: scenario_8\n",
      "Procesando escenario: scenario_9\n",
      "Procesando escenario: scenario_10\n",
      "Procesando escenario: scenario_11\n",
      "Procesando escenario: scenario_12\n",
      "Procesando escenario: scenario_13\n",
      "Procesando escenario: scenario_14\n",
      "Procesando escenario: scenario_15\n",
      "Procesando escenario: scenario_16\n",
      "Procesando escenario: scenario_17\n",
      "Procesando escenario: scenario_18\n",
      "Procesando escenario: scenario_19\n",
      "Procesando escenario: scenario_20\n",
      "Procesando escenario: scenario_21\n",
      "Procesando escenario: scenario_22\n",
      "Procesando escenario: scenario_23\n",
      "Procesando escenario: scenario_24\n",
      "Procesando escenario: scenario_25\n",
      "Procesando escenario: scenario_26\n",
      "Procesando escenario: scenario_27\n",
      "Procesando escenario: scenario_28\n",
      "Procesando escenario: scenario_29\n",
      "Procesando escenario: scenario_30\n",
      "Procesando escenario: scenario_31\n",
      "Procesando escenario: scenario_32\n",
      "Procesando escenario: scenario_33\n",
      "Procesando escenario: scenario_34\n",
      "Procesando escenario: scenario_35\n",
      "Procesando escenario: scenario_36\n",
      "Procesando escenario: scenario_37\n",
      "Procesando escenario: scenario_38\n",
      "Procesando escenario: scenario_39\n",
      "Procesando escenario: scenario_40\n",
      "Procesando escenario: scenario_41\n",
      "Procesando escenario: scenario_42\n",
      "Procesando escenario: scenario_43\n",
      "Procesando escenario: scenario_44\n",
      "Procesando escenario: scenario_45\n",
      "Procesando escenario: scenario_46\n",
      "Procesando escenario: scenario_47\n",
      "Procesando escenario: scenario_48\n",
      "Procesando escenario: scenario_49\n",
      "Procesando escenario: scenario_50\n",
      "Procesando escenario: scenario_51\n",
      "Procesando escenario: scenario_52\n",
      "Procesando escenario: scenario_53\n",
      "Procesando escenario: scenario_54\n",
      "Procesando escenario: scenario_55\n",
      "Procesando escenario: scenario_56\n",
      "Procesando escenario: scenario_57\n",
      "Procesando escenario: scenario_58\n",
      "Procesando escenario: scenario_59\n",
      "Procesando escenario: scenario_60\n",
      "Procesando escenario: scenario_61\n",
      "Procesando escenario: scenario_62\n",
      "Procesando escenario: scenario_63\n",
      "Procesando escenario: scenario_64\n",
      "Procesando escenario: scenario_65\n",
      "Procesando escenario: scenario_66\n",
      "Procesando escenario: scenario_67\n",
      "Procesando escenario: scenario_68\n",
      "Procesamiento completado. Se generaron 6800 pares de relés.\n",
      "Guardando lista de pares en: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/independent_relay_pairs.json\n",
      "¡Proceso completado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import copy # Para crear copias independientes de los diccionarios de relés\n",
    "\n",
    "# --- Constantes para el cálculo de Time_out ---\n",
    "K = 0.14\n",
    "N = 0.02\n",
    "DECIMAL_PLACES = 4\n",
    "\n",
    "# --- Rutas de los archivos ---\n",
    "data_coordination_file = \"/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/raw/data_coordination.json\"\n",
    "# Cambiado según solicitud: apunta al archivo (presumiblemente renombrado) 'relay_values.json'\n",
    "relay_values_file = \"/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/raw/optimized_relay_values.json\"\n",
    "# El archivo de salida contendrá la LISTA de pares con la nueva estructura\n",
    "output_pairs_file = \"/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/independent_relay_pairs.json\" # Nuevo nombre para evitar sobreescribir\n",
    "\n",
    "# --- Función para eliminar timestamps recursivamente ---\n",
    "def eliminar_timestamp(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        obj.pop(\"timestamp\", None)\n",
    "        for valor in obj.values():\n",
    "            eliminar_timestamp(valor)\n",
    "    elif isinstance(obj, list):\n",
    "        for elemento in obj:\n",
    "            eliminar_timestamp(elemento)\n",
    "\n",
    "# --- Función para calcular el tiempo de operación (Time_out) ---\n",
    "def calculate_operation_time(I_shc, I_pi, TDS):\n",
    "    # (Sin cambios en la función de cálculo)\n",
    "    if not all(isinstance(x, (int, float)) for x in [I_shc, I_pi, TDS]): return 0.0\n",
    "    if any(x is None or x <= 0 for x in [I_pi, TDS]): return 0.0\n",
    "    if I_shc < 0: return 0.0\n",
    "    if I_shc == 0: return 0.0\n",
    "    try:\n",
    "        if abs(I_pi) < 1e-9: return 0.0\n",
    "        M = I_shc / I_pi\n",
    "    except ZeroDivisionError: return 0.0\n",
    "    if M <= 1: return 0.0\n",
    "    try:\n",
    "        denominator = M**N - 1\n",
    "        if abs(denominator) < 1e-9: return 0.0\n",
    "        timeout = (K / denominator) * TDS\n",
    "        return round(timeout, DECIMAL_PLACES) if np.isfinite(timeout) else 0.0\n",
    "    except (OverflowError, ValueError): return 0.0\n",
    "    except Exception: return 0.0\n",
    "\n",
    "\n",
    "# --- Procesamiento Principal ---\n",
    "relay_pairs_list = []\n",
    "processed_scenarios_base = {}\n",
    "\n",
    "try:\n",
    "    # 1. Cargar y pre-procesar los datos base de coordinación\n",
    "    print(f\"Cargando datos base desde: {data_coordination_file}\")\n",
    "    with open(data_coordination_file, 'r') as archivo:\n",
    "        datos_coordinacion = json.load(archivo)\n",
    "\n",
    "    for escenario_base in datos_coordinacion:\n",
    "        scenario_id = escenario_base.get(\"scenario_id\")\n",
    "        if scenario_id:\n",
    "            escenario_procesado = escenario_base.copy()\n",
    "            escenario_procesado.pop(\"_id\", None)\n",
    "            escenario_procesado.pop(\"scenario_id\", None)\n",
    "            eliminar_timestamp(escenario_procesado)\n",
    "            processed_scenarios_base[scenario_id] = escenario_procesado\n",
    "    print(f\"Datos base cargados y pre-procesados para {len(processed_scenarios_base)} escenarios.\")\n",
    "\n",
    "    # 2. Cargar los valores de los relés (antes 'optimizados')\n",
    "    print(f\"Cargando valores de relés desde: {relay_values_file}\")\n",
    "    with open(relay_values_file, 'r') as archivo:\n",
    "        # Renombrado: datos_relay_values\n",
    "        datos_relay_values = json.load(archivo)\n",
    "    # Renombrado: relay_values_map\n",
    "    # ASUNCIÓN: La clave DENTRO del JSON ahora es 'relay_values'.\n",
    "    # Si sigue siendo 'optimized_relay_values', cambia el .get() abajo.\n",
    "    relay_values_map = {esc.get(\"scenario_id\"): esc.get(\"relay_values\", {})\n",
    "                        for esc in datos_relay_values if esc.get(\"scenario_id\")}\n",
    "    print(f\"Valores de relés cargados para {len(relay_values_map)} escenarios.\")\n",
    "\n",
    "    # 3. Fusionar, calcular timeouts y CONSTRUIR LISTA DE PARES (con línea en main_relay)\n",
    "    print(\"Procesando escenarios para crear pares de relés independientes...\")\n",
    "    pair_count = 0\n",
    "    for scenario_id, escenario_data in processed_scenarios_base.items():\n",
    "        print(f\"Procesando escenario: {scenario_id}\")\n",
    "        # Renombrado: current_relay_values\n",
    "        current_relay_values = relay_values_map.get(scenario_id)\n",
    "\n",
    "        if not current_relay_values:\n",
    "            print(f\"  Advertencia: No se encontraron valores de relé para {scenario_id}. Omitiendo pares de este escenario.\")\n",
    "            continue\n",
    "\n",
    "        # Iterar sobre las líneas (como \"L1-2\")\n",
    "        for linea_key, linea_data in escenario_data.items():\n",
    "             if isinstance(linea_data, dict) and 'scenarios' in linea_data:\n",
    "                # Iterar sobre los escenarios internos/fallas (como \"90\")\n",
    "                for fault_key, internal_scenario_data in linea_data.get('scenarios', {}).items():\n",
    "                    main_relay_info_orig = internal_scenario_data.get('main')\n",
    "                    backups_orig = internal_scenario_data.get('backups', [])\n",
    "\n",
    "                    if isinstance(main_relay_info_orig, dict) and isinstance(backups_orig, list):\n",
    "                        # Procesar relé principal UNA VEZ\n",
    "                        main_relay_info = copy.deepcopy(main_relay_info_orig)\n",
    "                        main_relay_name = main_relay_info.get('relay')\n",
    "                        main_time_out = 0.0\n",
    "\n",
    "                        # --- Añadir la línea principal AL OBJETO main_relay ---\n",
    "                        main_relay_info['line'] = linea_key\n",
    "                        # ----------------------------------------------------\n",
    "\n",
    "                        # Renombrado: current_relay_values\n",
    "                        if main_relay_name and main_relay_name in current_relay_values:\n",
    "                            # Renombrado: relay_setting\n",
    "                            relay_setting = current_relay_values[main_relay_name]\n",
    "                            main_relay_info['TDS'] = relay_setting.get('TDS')\n",
    "                            main_relay_info['pick_up'] = relay_setting.get('pickup')\n",
    "                            ishc = main_relay_info.get('Ishc')\n",
    "                            pickup = main_relay_info.get('pick_up')\n",
    "                            tds = main_relay_info.get('TDS')\n",
    "                            main_time_out = calculate_operation_time(ishc, pickup, tds)\n",
    "                            main_relay_info['Time_out'] = main_time_out\n",
    "                        else:\n",
    "                             ishc = main_relay_info.get('Ishc')\n",
    "                             pickup = main_relay_info.get('pick_up')\n",
    "                             tds = main_relay_info.get('TDS')\n",
    "                             main_time_out = calculate_operation_time(ishc, pickup, tds)\n",
    "                             main_relay_info['Time_out'] = main_time_out\n",
    "\n",
    "                        # Iterar sobre CADA relé de respaldo\n",
    "                        for backup_relay_info_orig in backups_orig:\n",
    "                            if isinstance(backup_relay_info_orig, dict):\n",
    "                                backup_relay_info = copy.deepcopy(backup_relay_info_orig)\n",
    "                                backup_relay_name = backup_relay_info.get('relay')\n",
    "                                backup_time_out = 0.0\n",
    "\n",
    "                                # Renombrado: current_relay_values\n",
    "                                if backup_relay_name and backup_relay_name in current_relay_values:\n",
    "                                    # Renombrado: relay_setting\n",
    "                                    relay_setting = current_relay_values[backup_relay_name]\n",
    "                                    backup_relay_info['TDS'] = relay_setting.get('TDS')\n",
    "                                    backup_relay_info['pick_up'] = relay_setting.get('pickup')\n",
    "                                    ishc = backup_relay_info.get('Ishc')\n",
    "                                    pickup = backup_relay_info.get('pick_up')\n",
    "                                    tds = backup_relay_info.get('TDS')\n",
    "                                    backup_time_out = calculate_operation_time(ishc, pickup, tds)\n",
    "                                    backup_relay_info['Time_out'] = backup_time_out\n",
    "                                else:\n",
    "                                    ishc = backup_relay_info.get('Ishc')\n",
    "                                    pickup = backup_relay_info.get('pick_up')\n",
    "                                    tds = backup_relay_info.get('TDS')\n",
    "                                    backup_time_out = calculate_operation_time(ishc, pickup, tds)\n",
    "                                    backup_relay_info['Time_out'] = backup_time_out\n",
    "\n",
    "                                # Crear el diccionario del par (SIN 'line' de nivel superior)\n",
    "                                pair_entry = {\n",
    "                                    \"scenario_id\": scenario_id,\n",
    "                                    # \"line\": linea_key, # <-- Eliminado de aquí\n",
    "                                    \"fault\": fault_key,\n",
    "                                    \"main_relay\": main_relay_info, # Ya contiene 'line'\n",
    "                                    \"backup_relay\": backup_relay_info # Mantiene su 'line' interna opcional\n",
    "                                }\n",
    "                                relay_pairs_list.append(pair_entry)\n",
    "                                pair_count += 1\n",
    "\n",
    "    print(f\"Procesamiento completado. Se generaron {pair_count} pares de relés.\")\n",
    "\n",
    "    # 4. Guardar la LISTA de pares en el archivo de salida\n",
    "    print(f\"Guardando lista de pares en: {output_pairs_file}\")\n",
    "    output_dir = os.path.dirname(output_pairs_file)\n",
    "    if output_dir: os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(output_pairs_file, 'w') as f:\n",
    "        json.dump(relay_pairs_list, f, indent=2)\n",
    "\n",
    "    print(\"¡Proceso completado exitosamente!\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error CRÍTICO: No se pudo encontrar el archivo: {e.filename}\")\n",
    "    print(\"Verifica que las rutas y nombres de archivo sean correctos (especialmente 'relay_values.json').\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error CRÍTICO: El archivo JSON está mal formado: {e}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Falta una clave esperada en los datos: {e}\")\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"Error inesperado durante el procesamiento: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25447e",
   "metadata": {},
   "source": [
    "# Filtrar por pares buenos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d29121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han guardado 3400 pares en:\n",
      "/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/independent_relay_pairs_best.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Ruta de tu archivo original\n",
    "input_path  = '/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/independent_relay_pairs.json'\n",
    "# Ruta donde quieres guardar el filtrado\n",
    "output_path = '/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/independent_relay_pairs_best.json'\n",
    "\n",
    "# 1. Cargar JSON original\n",
    "with open(input_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 2. Lista de escenarios considerados “Buenos”\n",
    "buenos = [\n",
    "    \"scenario_29\", \"scenario_4\", \"scenario_24\", \"scenario_31\", \"scenario_36\", \n",
    "    \"scenario_25\", \"scenario_55\", \"scenario_26\", \"scenario_30\", \"scenario_21\", \n",
    "    \"scenario_57\", \"scenario_56\", \"scenario_34\", \"scenario_54\", \"scenario_23\", \n",
    "    \"scenario_63\", \"scenario_58\", \"scenario_1\",  \"scenario_33\", \"scenario_66\", \n",
    "    \"scenario_22\", \"scenario_59\", \"scenario_28\", \"scenario_67\", \"scenario_53\", \n",
    "    \"scenario_60\", \"scenario_27\", \"scenario_32\", \"scenario_35\", \"scenario_68\", \n",
    "    \"scenario_62\", \"scenario_61\", \"scenario_64\", \"scenario_65\"\n",
    "]\n",
    "\n",
    "# 3. Filtrar sólo las entradas cuyo 'scenario_id' esté en la lista de buenos\n",
    "filtered = [item for item in data if item.get('scenario_id') in buenos]\n",
    "\n",
    "# 4. Guardar el resultado en el nuevo JSON\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(filtered, f, indent=2)\n",
    "\n",
    "print(f'Se han guardado {len(filtered)} pares en:\\n{output_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4906190b",
   "metadata": {},
   "source": [
    "# Eliminar TDS & Pickup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb80b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de entrada: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/independent_relay_pairs_bad.json\n",
      "Archivo de salida: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/model/input_data.json\n",
      "Cargando datos (lista de pares) desde el archivo de entrada...\n",
      "Datos cargados correctamente.\n",
      "Procesando datos para eliminar 'pick_up' y 'TDS' de cada par...\n",
      "Procesamiento completado. Se procesaron 3400 pares.\n",
      "Se modificaron (eliminando pick_up/TDS de main o backup) 6732 diccionarios de relé.\n",
      "Guardando datos modificados en: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/model/input_data.json\n",
      "¡Archivo guardado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import copy # Usaremos deepcopy para asegurar que no modificamos el original\n",
    "\n",
    "# --- Rutas de los archivos ---\n",
    "# Archivo de entrada es la lista de pares generada anteriormente\n",
    "input_file = \"/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/independent_relay_pairs_bad.json\"\n",
    "\n",
    "# Nombre del archivo de salida final según tu solicitud\n",
    "output_file = \"/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/model/input_data.json\"\n",
    "\n",
    "print(f\"Archivo de entrada: {input_file}\")\n",
    "print(f\"Archivo de salida: {output_file}\")\n",
    "\n",
    "try:\n",
    "    # 1. Cargar el archivo JSON existente (que es una LISTA)\n",
    "    print(\"Cargando datos (lista de pares) desde el archivo de entrada...\")\n",
    "    with open(input_file, 'r') as f:\n",
    "        # Ahora 'data' será una lista de diccionarios\n",
    "        data = json.load(f)\n",
    "    print(\"Datos cargados correctamente.\")\n",
    "\n",
    "    # Verificar que los datos cargados son una lista\n",
    "    if not isinstance(data, list):\n",
    "        raise TypeError(f\"Error: El archivo de entrada {input_file} no contiene una lista JSON como se esperaba.\")\n",
    "\n",
    "    # Crear una copia profunda para modificarla\n",
    "    modified_data = copy.deepcopy(data)\n",
    "\n",
    "    # 2. Iterar sobre la LISTA y eliminar las claves 'pick_up' y 'TDS' de cada par\n",
    "    print(\"Procesando datos para eliminar 'pick_up' y 'TDS' de cada par...\")\n",
    "    pairs_processed = 0\n",
    "    relays_modified_count = 0 # Contará cuántos diccionarios (main o backup) fueron modificados\n",
    "\n",
    "    # Iterar directamente sobre cada diccionario 'pair_entry' en la lista 'modified_data'\n",
    "    for pair_entry in modified_data:\n",
    "        if isinstance(pair_entry, dict):\n",
    "            # Procesar el diccionario del relé principal\n",
    "            main_relay_info = pair_entry.get('main_relay')\n",
    "            if isinstance(main_relay_info, dict):\n",
    "                # Eliminar claves si existen, si no, no hacer nada\n",
    "                # pop devuelve el valor eliminado o None, is not None verifica si se eliminó algo\n",
    "                key_removed_main = main_relay_info.pop('pick_up', None) is not None\n",
    "                key_removed_main = main_relay_info.pop('TDS', None) is not None or key_removed_main # Se actualiza si alguna de las dos se eliminó\n",
    "                if key_removed_main:\n",
    "                    relays_modified_count += 1\n",
    "\n",
    "            # Procesar el diccionario del relé de respaldo\n",
    "            backup_relay_info = pair_entry.get('backup_relay')\n",
    "            if isinstance(backup_relay_info, dict):\n",
    "                # Eliminar claves si existen\n",
    "                key_removed_backup = backup_relay_info.pop('pick_up', None) is not None\n",
    "                key_removed_backup = backup_relay_info.pop('TDS', None) is not None or key_removed_backup\n",
    "                if key_removed_backup:\n",
    "                    relays_modified_count += 1\n",
    "\n",
    "            pairs_processed += 1 # Incrementar el contador de pares procesados\n",
    "        else:\n",
    "            print(f\"Advertencia: Se encontró un elemento no diccionario en la lista: {pair_entry}\")\n",
    "\n",
    "\n",
    "    print(f\"Procesamiento completado. Se procesaron {pairs_processed} pares.\")\n",
    "    print(f\"Se modificaron (eliminando pick_up/TDS de main o backup) {relays_modified_count} diccionarios de relé.\")\n",
    "\n",
    "    # 3. Guardar los datos modificados (la lista) en un nuevo archivo JSON\n",
    "    print(f\"Guardando datos modificados en: {output_file}\")\n",
    "    # Crear directorio si no existe (opcional pero buena práctica)\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Guardar la lista modificada directamente\n",
    "        json.dump(modified_data, f, indent=2)\n",
    "\n",
    "    print(\"¡Archivo guardado exitosamente!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error CRÍTICO: No se pudo encontrar el archivo de entrada: {input_file}\")\n",
    "    print(\"Por favor, verifica que la ruta y el nombre del archivo sean correctos.\")\n",
    "except TypeError as e:\n",
    "    print(e) # Imprimir el mensaje de error si el archivo no es una lista\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error CRÍTICO: El archivo de entrada JSON ({input_file}) está mal formado: {e}\")\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"Error inesperado durante el procesamiento: {e}\")\n",
    "    print(\"--- Traceback ---\")\n",
    "    traceback.print_exc()\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6372efe",
   "metadata": {},
   "source": [
    "# Update Inom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6224cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de resultados de flujo de carga: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/raw/load_flow_results.json\n",
      "Archivo de pares de relés (entrada y salida): /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/model/input_data.json\n",
      "NOTA: Se espera que la clave 'line' esté DENTRO del objeto 'main_relay' en el archivo de entrada.\n",
      "Cargando y pre-procesando resultados de flujo de carga...\n",
      "Resultados de flujo de carga pre-procesados para 68 escenarios.\n",
      "Cargando datos de pares de relés desde: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/model/input_data.json\n",
      "Datos de pares de relés cargados.\n",
      "Añadiendo valores de 'current_a' a los pares de relés...\n",
      "Procesamiento completado.\n",
      "Se procesaron 3400 pares de relés del archivo.\n",
      "Se añadieron/actualizaron valores de 'current_a' a 6800 entradas de relé (main o backup).\n",
      "Guardando datos actualizados en: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/model/input_data.json\n",
      "¡Archivo /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/model/input_data.json actualizado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "# No necesitamos copy esta vez, modificaremos la estructura cargada directamente\n",
    "\n",
    "# --- Rutas de los archivos ---\n",
    "load_flow_file = \"/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/raw/load_flow_results.json\"\n",
    "# El archivo que contiene los pares de relés (con 'line' DENTRO de 'main_relay')\n",
    "# y que será MODIFICADO\n",
    "# ASUNCIÓN: Este archivo es el resultado del script anterior (ej. 'independent_relay_pairs_v2.json')\n",
    "#           El usuario lo llama 'input_data.json' en el prompt, así que usamos esa ruta.\n",
    "#           ¡Asegúrate de que este archivo tenga la estructura correcta!\n",
    "relay_pairs_file = \"/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/model/input_data.json\"\n",
    "\n",
    "\n",
    "print(f\"Archivo de resultados de flujo de carga: {load_flow_file}\")\n",
    "print(f\"Archivo de pares de relés (entrada y salida): {relay_pairs_file}\")\n",
    "print(\"NOTA: Se espera que la clave 'line' esté DENTRO del objeto 'main_relay' en el archivo de entrada.\")\n",
    "\n",
    "# Diccionario para almacenar las corrientes por escenario y línea para búsqueda rápida\n",
    "load_flow_map = {}\n",
    "\n",
    "try:\n",
    "    # 1. Cargar y pre-procesar los resultados del flujo de carga\n",
    "    print(\"Cargando y pre-procesando resultados de flujo de carga...\")\n",
    "    with open(load_flow_file, 'r') as f:\n",
    "        load_flow_data = json.load(f)\n",
    "\n",
    "    if not isinstance(load_flow_data, list):\n",
    "        raise TypeError(f\"Error: El archivo {load_flow_file} no contiene una lista JSON.\")\n",
    "\n",
    "    for scenario_result in load_flow_data:\n",
    "        scenario_id = scenario_result.get(\"scenario_id\")\n",
    "        lines_data = scenario_result.get(\"lines\")\n",
    "\n",
    "        if scenario_id and isinstance(lines_data, list):\n",
    "            line_currents = {}\n",
    "            for line_info in lines_data:\n",
    "                line_name = line_info.get(\"name\")\n",
    "                current_a = line_info.get(\"current_a\")\n",
    "                if line_name and current_a is not None:\n",
    "                    line_currents[line_name] = current_a\n",
    "            load_flow_map[scenario_id] = line_currents\n",
    "\n",
    "    print(f\"Resultados de flujo de carga pre-procesados para {len(load_flow_map)} escenarios.\")\n",
    "    if not load_flow_map:\n",
    "        print(\"Advertencia: No se cargaron datos válidos del flujo de carga. El archivo de salida no se modificará.\")\n",
    "        exit()\n",
    "\n",
    "    # 2. Cargar el archivo de pares de relés (con la nueva estructura)\n",
    "    print(f\"Cargando datos de pares de relés desde: {relay_pairs_file}\")\n",
    "    with open(relay_pairs_file, 'r') as f:\n",
    "        relay_pairs_data = json.load(f)\n",
    "\n",
    "    if not isinstance(relay_pairs_data, list):\n",
    "         raise TypeError(f\"Error: El archivo {relay_pairs_file} no contiene una lista JSON de pares.\")\n",
    "    print(\"Datos de pares de relés cargados.\")\n",
    "\n",
    "    # 3. Iterar sobre los pares y añadir la corriente 'current_a'\n",
    "    print(\"Añadiendo valores de 'current_a' a los pares de relés...\")\n",
    "    pairs_processed = 0\n",
    "    currents_added_count = 0\n",
    "    missing_currents_warnings = 0\n",
    "\n",
    "    for pair_entry in relay_pairs_data:\n",
    "        pairs_processed += 1 # Contar cada par leído\n",
    "        if not isinstance(pair_entry, dict):\n",
    "            print(f\"Advertencia: Se encontró un elemento no diccionario en {relay_pairs_file}. Omitido.\")\n",
    "            continue\n",
    "\n",
    "        scenario_id = pair_entry.get(\"scenario_id\")\n",
    "        main_relay_info = pair_entry.get(\"main_relay\")\n",
    "        backup_relay_info = pair_entry.get(\"backup_relay\")\n",
    "\n",
    "        # --- Obtener Main Line Name desde DENTRO de main_relay_info ---\n",
    "        main_line_name = None\n",
    "        if isinstance(main_relay_info, dict):\n",
    "            main_line_name = main_relay_info.get(\"line\") # Busca la clave 'line' aquí\n",
    "        # -------------------------------------------------------------\n",
    "\n",
    "        if not scenario_id:\n",
    "            print(f\"Advertencia: Par omitido por falta de 'scenario_id': {pair_entry}\")\n",
    "            continue\n",
    "\n",
    "        scenario_currents = load_flow_map.get(scenario_id)\n",
    "        if not scenario_currents:\n",
    "            # print(f\"Advertencia: No se encontraron datos de flujo de carga para scenario_id='{scenario_id}'. Asignando 'null' a 'current_a'.\")\n",
    "            if isinstance(main_relay_info, dict): main_relay_info['current_a'] = None\n",
    "            if isinstance(backup_relay_info, dict): backup_relay_info['current_a'] = None\n",
    "            missing_currents_warnings += 1\n",
    "            continue\n",
    "\n",
    "        # --- Añadir corriente al relé principal ---\n",
    "        if isinstance(main_relay_info, dict):\n",
    "            if main_line_name: # Solo proceder si obtuvimos un nombre de línea\n",
    "                current_a_main = scenario_currents.get(main_line_name)\n",
    "                if current_a_main is not None:\n",
    "                    main_relay_info['current_a'] = current_a_main\n",
    "                    currents_added_count += 1\n",
    "                else:\n",
    "                    main_relay_info['current_a'] = None # Se buscó línea pero no corriente\n",
    "                    missing_currents_warnings += 1\n",
    "                    # print(f\"Advertencia: No se encontró 'current_a' para scenario='{scenario_id}', línea principal='{main_line_name}'.\")\n",
    "            else:\n",
    "                main_relay_info['current_a'] = None # No se encontró 'line' en main_relay\n",
    "                missing_currents_warnings += 1\n",
    "                # print(f\"Advertencia: No se encontró clave 'line' en main_relay para scenario='{scenario_id}'.\")\n",
    "        # Si main_relay_info no es dict, no se hace nada.\n",
    "\n",
    "        # --- Añadir corriente al relé de respaldo ---\n",
    "        if isinstance(backup_relay_info, dict):\n",
    "            # Determinar línea de respaldo: la suya propia o la principal (que puede ser None)\n",
    "            backup_line_name = backup_relay_info.get('line', main_line_name)\n",
    "\n",
    "            if backup_line_name: # Si se pudo determinar un nombre de línea\n",
    "                current_a_backup = scenario_currents.get(backup_line_name)\n",
    "                if current_a_backup is not None:\n",
    "                    backup_relay_info['current_a'] = current_a_backup\n",
    "                    currents_added_count += 1\n",
    "                else:\n",
    "                    backup_relay_info['current_a'] = None # Se buscó línea pero no corriente\n",
    "                    missing_currents_warnings += 1\n",
    "                    # print(f\"Advertencia: No se encontró 'current_a' para scenario='{scenario_id}', línea respaldo='{backup_line_name}'.\")\n",
    "            else:\n",
    "                 backup_relay_info['current_a'] = None # No se pudo determinar nombre de línea\n",
    "                 missing_currents_warnings += 1\n",
    "                 # print(f\"Advertencia: No se pudo determinar línea para backup_relay en scenario='{scenario_id}'.\")\n",
    "        # Si backup_relay_info no es dict, no se hace nada.\n",
    "\n",
    "\n",
    "    print(f\"Procesamiento completado.\")\n",
    "    print(f\"Se procesaron {pairs_processed} pares de relés del archivo.\")\n",
    "    print(f\"Se añadieron/actualizaron valores de 'current_a' a {currents_added_count} entradas de relé (main o backup).\")\n",
    "    if missing_currents_warnings > 0:\n",
    "        print(f\"Hubo {missing_currents_warnings} casos donde no se encontró la clave 'line' o el valor 'current_a' correspondiente (se asignó 'null').\")\n",
    "\n",
    "    # 4. Guardar los datos modificados DE VUELTA al archivo original\n",
    "    print(f\"Guardando datos actualizados en: {relay_pairs_file}\")\n",
    "    with open(relay_pairs_file, 'w') as f:\n",
    "        json.dump(relay_pairs_data, f, indent=2)\n",
    "\n",
    "    print(f\"¡Archivo {relay_pairs_file} actualizado exitosamente!\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error CRÍTICO: No se pudo encontrar un archivo necesario: {e.filename}\")\n",
    "    print(\"Verifica las rutas de 'load_flow_results.json' y 'input_data.json'.\")\n",
    "except TypeError as e:\n",
    "    print(f\"Error CRÍTICO: Problema con el tipo de datos esperado en un archivo JSON: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error CRÍTICO: Un archivo JSON está mal formado: {e}\")\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"Error inesperado durante el procesamiento: {e}\")\n",
    "    print(\"--- Traceback ---\")\n",
    "    traceback.print_exc()\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c5143",
   "metadata": {},
   "source": [
    "# crear json de referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac750a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de entrada: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/independent_relay_pairs_best.json\n",
      "Archivo de salida: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/model/reference_data.json\n",
      "Cargando datos (lista de pares) desde el archivo de entrada...\n",
      "Datos cargados correctamente.\n",
      "Procesando datos para dejar 'pick_up' y 'TDS' de cada par...\n",
      "Procesamiento completado. Se procesaron 3400 pares.\n",
      "Se modificaron (eliminando pick_up/TDS de main o backup) 6800 diccionarios de relé.\n",
      "Guardando datos modificados en: /Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/model/reference_data.json\n",
      "¡Archivo guardado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import copy # Usaremos deepcopy para asegurar que no modificamos el original\n",
    "\n",
    "# --- Rutas de los archivos ---\n",
    "# Archivo de entrada es la lista de pares generada anteriormente\n",
    "input_file = \"/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/independent_relay_pairs_best.json\"\n",
    "\n",
    "# Nombre del archivo de salida final según tu solicitud\n",
    "output_file = \"/Users/gustavo/Documents/Projects/TESIS_UNAL/ADAPTIVE_ALGORITHM/data/processed/model/reference_data.json\"\n",
    "\n",
    "print(f\"Archivo de entrada: {input_file}\")\n",
    "print(f\"Archivo de salida: {output_file}\")\n",
    "\n",
    "try:\n",
    "    # 1. Cargar el archivo JSON existente (que es una LISTA)\n",
    "    print(\"Cargando datos (lista de pares) desde el archivo de entrada...\")\n",
    "    with open(input_file, 'r') as f:\n",
    "        # Ahora 'data' será una lista de diccionarios\n",
    "        data = json.load(f)\n",
    "    print(\"Datos cargados correctamente.\")\n",
    "\n",
    "    # Verificar que los datos cargados son una lista\n",
    "    if not isinstance(data, list):\n",
    "        raise TypeError(f\"Error: El archivo de entrada {input_file} no contiene una lista JSON como se esperaba.\")\n",
    "\n",
    "    # Crear una copia profunda para modificarla\n",
    "    modified_data = copy.deepcopy(data)\n",
    "\n",
    "    # 2. Iterar sobre la LISTA y eliminar las claves 'pick_up' y 'TDS' de cada par\n",
    "    print(\"Procesando datos para dejar 'pick_up' y 'TDS' de cada par...\")\n",
    "    pairs_processed = 0\n",
    "    relays_modified_count = 0 # Contará cuántos diccionarios (main o backup) fueron modificados\n",
    "\n",
    "    # Iterar directamente sobre cada diccionario 'pair_entry' en la lista 'modified_data'\n",
    "    for pair_entry in modified_data:\n",
    "        if isinstance(pair_entry, dict):\n",
    "            # Procesar el diccionario del relé principal\n",
    "            main_relay_info = pair_entry.get('main_relay')\n",
    "            if isinstance(main_relay_info, dict):\n",
    "                # Eliminar claves si existen, si no, no hacer nada\n",
    "                # pop devuelve el valor eliminado o None, is not None verifica si se eliminó algo\n",
    "                key_removed_main = main_relay_info.pop('Ishc', None) is not None\n",
    "                key_removed_main = main_relay_info.pop('Time_out', None) is not None or key_removed_main # Se actualiza si alguna de las dos se eliminó\n",
    "                if key_removed_main:\n",
    "                    relays_modified_count += 1\n",
    "\n",
    "            # Procesar el diccionario del relé de respaldo\n",
    "            backup_relay_info = pair_entry.get('backup_relay')\n",
    "            if isinstance(backup_relay_info, dict):\n",
    "                # Eliminar claves si existen\n",
    "                key_removed_backup = backup_relay_info.pop('Time_out', None) is not None\n",
    "                key_removed_backup = backup_relay_info.pop('Ishc', None) is not None or key_removed_backup\n",
    "                if key_removed_backup:\n",
    "                    relays_modified_count += 1\n",
    "\n",
    "            pairs_processed += 1 # Incrementar el contador de pares procesados\n",
    "        else:\n",
    "            print(f\"Advertencia: Se encontró un elemento no diccionario en la lista: {pair_entry}\")\n",
    "\n",
    "\n",
    "    print(f\"Procesamiento completado. Se procesaron {pairs_processed} pares.\")\n",
    "    print(f\"Se modificaron (eliminando pick_up/TDS de main o backup) {relays_modified_count} diccionarios de relé.\")\n",
    "\n",
    "    # 3. Guardar los datos modificados (la lista) en un nuevo archivo JSON\n",
    "    print(f\"Guardando datos modificados en: {output_file}\")\n",
    "    # Crear directorio si no existe (opcional pero buena práctica)\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Guardar la lista modificada directamente\n",
    "        json.dump(modified_data, f, indent=2)\n",
    "\n",
    "    print(\"¡Archivo guardado exitosamente!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error CRÍTICO: No se pudo encontrar el archivo de entrada: {input_file}\")\n",
    "    print(\"Por favor, verifica que la ruta y el nombre del archivo sean correctos.\")\n",
    "except TypeError as e:\n",
    "    print(e) # Imprimir el mensaje de error si el archivo no es una lista\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error CRÍTICO: El archivo de entrada JSON ({input_file}) está mal formado: {e}\")\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"Error inesperado durante el procesamiento: {e}\")\n",
    "    print(\"--- Traceback ---\")\n",
    "    traceback.print_exc()\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9687e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
